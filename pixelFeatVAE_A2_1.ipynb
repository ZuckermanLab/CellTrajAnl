{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa3400-879c-43f6-a496-f4ae019330e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb46a1-ca9b-4013-b767-fa93620f84c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "model_path=\"/home/groups/ZuckermanLab/jalim/test_m2cO2vae/\"\n",
    "sys.path.append(model_path)\n",
    "import importlib\n",
    "import train_loops\n",
    "import run\n",
    "from utils import utils\n",
    "import wandb\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from configs.config_LI204601 import config # Load Pretrained Model Configuration\n",
    "from torchvision.utils import make_grid\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2584e0-f024-45f6-a40e-a0c156cb97e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Using Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef178862-5f29-49fc-a85f-db8787c1ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "\n",
    "dset, loader, dset_test, loader_test = run.get_datasets_from_config(config) # get datasets specified by config\n",
    "fig, axs = utils.plot_sample_data(loader) # Loading Training Set Images as per the batch size \n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b47fd-8921-4b03-93ec-8b0abe420356",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model.encoder.n_channels = dset[0][0].shape[0]  # image channels\n",
    "model = run.build_model_from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf26a2-8697-4247-a765-eafe9871033a",
   "metadata": {},
   "source": [
    "### Get pre-trained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b553b6-c8f5-4df6-951b-e1db095c2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path = os.path.join(model_path, \"wandb/offline-run-20240911_171039-egf1_1/files/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727f863-c31e-442f-814d-528784df1908",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint = torch.load(pretrained_model_path)\n",
    "#model.to(device).cpu().train() # if keys don't match, try many combinations of putting it on and off cuda\n",
    "model.to(device).train()\n",
    "missing_keys, unexpected_keys = model.load_state_dict(model_checkpoint['model_state_dict'], strict=False)\n",
    "assert all(['_basisexpansion' in k for k in missing_keys]) # checking that the only missing keys from the state_dict are this one type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb255d53-19ab-4015-bd3b-87077acac412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import eval_utils\n",
    "importlib.reload(eval_utils)\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#model.eval().cpu() \n",
    "model.eval().to(device)\n",
    "#model.to(device).cpu()\n",
    "model.to(device)\n",
    "x, y = next(iter(loader)) # One Batch: Training Set\n",
    "#x, y = next(iter(loader_test)) # One Batch: Test Set\n",
    "\n",
    "print(f\"x shape: {x.shape}, device: {x.device}\")\n",
    "print(f\"y shape: {y.shape}, device: {y.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f165568-6f7c-4379-8786-6a63fb5d9abb",
   "metadata": {},
   "source": [
    "### Run on CPU & Visualize the reconstruction grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599ec7a-85ec-40d5-8460-4d786646fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    reconstruct_grid_aligned = eval_utils.reconstruction_grid(model, x.to(device), align=True, device=device)\n",
    "except Exception as e:\n",
    "    print(f\"Error on CPU: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a53bc-9cf1-4990-8220-35bc8806a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(20, 20))\n",
    "axs.imshow(reconstruct_grid_aligned.numpy(), cmap='gray')\n",
    "axs.set_title('Reconstruction Grid Aligned')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6444edf-0efa-4608-9e9a-a45d016c8f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Variational AutoEncoder",
   "language": "python",
   "name": "o2vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
