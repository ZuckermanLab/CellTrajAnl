{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f9f73-1c5b-4023-b03d-905d9a6bc31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, os, time, math\n",
    "sys.path.append('/home/groups/ZuckermanLab/jalim/instalLocal/celltraj/celltraj')\n",
    "import jcTrajectory_CP as cellTraj\n",
    "import h5py\n",
    "import pickle\n",
    "import subprocess\n",
    "import umap\n",
    "import scipy\n",
    "from csaps import csaps\n",
    "import string\n",
    "from joblib import dump, load\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0e3fb-b76b-41fc-af6c-e345a4517459",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Parameters of transitions between \"macroscopic\" states ##########\n",
    "nstates_final = 7\n",
    "max_states = 100\n",
    "pcut_final = 0.094\n",
    "n_components_tMat = 15\n",
    "trajl = 40 # Trajectory Length for morphodynamical trajectory analysis\n",
    "wells_flg = 0 # Flag to import data of certain wells combinations\n",
    "\n",
    "if(wells_flg == 0):\n",
    "  wellsInfo = 'Awells'\n",
    "  conditions = ['A1','A2','A3','A4','A5','C1','C2','C3'] # LIGANDS (CONDITIONS)\n",
    "  tmSet = ['OSM1','EGF1','EGF+TGFB1','TGFB1','PBS1','OSM+EGF+TGFB','OSM+EGF','OSM+TGFB']\n",
    "elif(wells_flg == 1):\n",
    "  wellsInfo = 'Bwells'\n",
    "  conditions = ['B1','B2','B3','B4','B5','C1','C2','C3'] # LIGANDS (CONDITIONS)\n",
    "  tmSet = ['OSM2','EGF2','EGF+TGFB2','TGFB2','PBS2','OSM+EGF+TGFB','OSM+EGF','OSM+TGFB']\n",
    "else:\n",
    "  wellsInfo = 'AllWells'\n",
    "  conditions = ['A1','A2','A3','A4','A5','B1','B2','B3','B4','B5','C1','C2','C3'] # LIGANDS (CONDITIONS)\n",
    "  tmSet = ['OSM1','EGF1','EGF+TGFB1','TGFB1','PBS1','OSM2','EGF2','EGF+TGFB2','TGFB2','PBS2','OSM+EGF+TGFB','OSM+EGF','OSM+TGFB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ebe5b-10e7-4c89-a4e1-9f014ac6416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nConditions = len(tmSet) # Total number of Ligand Conditions\n",
    "#os.environ['OMP_NUM_THREADS'] = '1'; os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "today = date.today()\n",
    "date2day = today.strftime(\"%b%d-%Y\")\n",
    "sysName = 'LI204601_P'\n",
    "figid = sysName+'_tlen'+str(trajl)+'_'+date2day\n",
    "\n",
    "# Indices for the ligands \n",
    "inds_tmSet = [i for i in range(nConditions)]\n",
    "inds_tmSet = np.array(inds_tmSet).astype(int)\n",
    "nfovs = 4\n",
    "fovs = [i for i in range(1, nfovs + 1)]\n",
    "fovs = np.array(fovs).astype(int)\n",
    "dateSet = ['']\n",
    "pathSet = ['/home/groups/ZuckermanLab/jalim/LI204601_INCUCYTE/segsCellPose/bayesianTrackTest/']\n",
    "imagingSet = [0 for i in range(nConditions)]\n",
    "modelList = [None]*(nfovs*(nConditions))\n",
    "modelList_conditions = np.zeros(nfovs*(nConditions)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf28618-ac83-4dda-8632-e4b99d9686d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "icond = 0\n",
    "for cond in conditions:\n",
    "    for fov in fovs:\n",
    "        modelList_conditions[i] = icond\n",
    "        modelList[i] = pathSet[imagingSet[icond]]+sysName+'_'+cond+'_'+str(fov)+dateSet[imagingSet[icond]]\n",
    "        #print(\"Models: \",modelList[i])\n",
    "        i = i + 1\n",
    "    icond = icond + 1\n",
    "\n",
    "nmodels = len(modelList)\n",
    "modelSet = [None]*nmodels\n",
    "indgood_models = np.array([]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1186e6e6-bcfe-4f25-b1fb-74693993ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nmodels):\n",
    "    try:\n",
    "        objFile = modelList[i]+'.obj'\n",
    "        objFileHandler = open(objFile,'rb')\n",
    "        modelSet[i] = pickle.load(objFileHandler)\n",
    "        print('loaded '+objFile+' with '+str(modelSet[i].cells_indSet.size)+' cells')\n",
    "        objFileHandler.close()\n",
    "        test = len(modelSet[i].linSet)\n",
    "        indgood_models = np.append(indgood_models,i)\n",
    "    except:\n",
    "        print(\"ERROR in reading *.obj files\")\n",
    "        sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb6c82-bd37-4b87-85e0-1121406521c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of frames (image snapshots) in one condition per FOVs\n",
    "nframes = 193 \n",
    "cellnumber_stdSet = np.ones(nmodels)*np.inf\n",
    "# range of frame indices where cell numbers are higher: ~70-98%\n",
    "sframe = 70.*nframes/100.; sframe = math.ceil(sframe)\n",
    "eframe = 98.5*nframes/100.; eframe = math.ceil(eframe)\n",
    "cellnumber_frames = np.arange(sframe, eframe).astype(int)\n",
    "cellnumber_std_cut = .50 # This was set to 0.10 by Jeremy \n",
    "frames = np.arange(nframes)\n",
    "# Abscissas at which smoothing will be done using CSAPS package\n",
    "abSmooth = np.linspace(frames[0], frames[-1], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51aca4-8c01-491d-a585-ca8c22f84243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.clf()\n",
    "#plt.figure(figsize = (8, 7))\n",
    "with open('cellNumbers.dat', 'w', encoding = 'utf-8') as fp: # PRINT cell numbers in a file for each model\n",
    "     for i in indgood_models:\n",
    "        ncells = np.zeros(nframes)\n",
    "        ncells_smooth = np.zeros_like(ncells)\n",
    "        for iS in range(nframes):\n",
    "           ncells[iS]=np.sum(modelSet[i].cells_frameSet==iS)\n",
    "           fp.write(str(ncells[iS])+\"\\t\")\n",
    "           fp.write(\"\\n\")\n",
    "        # Cubic Spline Approximation (CSAPS) to smoothen the data\n",
    "        splfov = csaps(frames, ncells/ncells[0], abSmooth, smooth = 0.98) # Scaled by ncells[0] to avoid large numbers\n",
    "        ncells_smooth = splfov*ncells[0] # smoothened cell numbers reverse scaled back to original\n",
    "        cellnumber_std = np.std(ncells[cellnumber_frames] - ncells_smooth[cellnumber_frames])/np.mean(ncells[cellnumber_frames])\n",
    "        cellnumber_stdSet[i] = cellnumber_std # Standard Deviation in Cell Numbers\t\t\n",
    "        #print(\"cellnumber_stdSet[\",i,\"] = \", cellnumber_std)\n",
    "        #plt.plot(ncells/ncells[0], color = colModels[i], label = capModels[i])\n",
    "        #plt.plot(ncells, color = colModels[i], label = capModels[i])\n",
    "        #plt.plot(ncells/ncells[0]); plt.pause(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdaec06-322c-49db-95dd-908ee14e33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "indhigh_std = np.where(cellnumber_stdSet > cellnumber_std_cut)[0]\n",
    "indgood_models = np.setdiff1d(indgood_models, indhigh_std)\n",
    "#indgood_models = np.setdiff1d(indgood_models, np.array([51]).astype(int)) #missing comdx for EGF0_4\n",
    "\n",
    "# get cell counts\n",
    "nf = len(tmSet)\n",
    "inds_tmSet_models = np.zeros(nmodels).astype(int)\n",
    "inds_imagingSet_models = np.zeros(nmodels).astype(int)\n",
    "i = 0\n",
    "icond = 0\n",
    "for cond in conditions:\n",
    "    for fov in fovs:\n",
    "        inds_tmSet_models[i] = inds_tmSet[icond]\n",
    "        inds_imagingSet_models[i] = imagingSet[icond]\n",
    "        i = i + 1\n",
    "    icond = icond + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd83b6-3f21-4ba4-a0f4-3bba0626a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indgood_models:\n",
    "    if inds_imagingSet_models[i] == 0:\n",
    "        modelSet[i].Xf[np.isnan(modelSet[i].Xf)] = 0.0 #just replace with zeros for now? Not sure best..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d04cff-6e16-4a08-ab86-c70e19880421",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeat_com = 3\n",
    "Xf_com0 = np.zeros((0, nfeat_com))\n",
    "for i in indgood_models:\n",
    "    if inds_imagingSet_models[i] == 0:\n",
    "        Xf_com0 = np.append(Xf_com0,modelSet[i].Xf_com, axis = 0)\n",
    "\n",
    "av_dx = np.nanmean(Xf_com0[:, 0])\n",
    "std_dx = np.nanstd(Xf_com0[:, 0])\n",
    "for i in indgood_models:\n",
    "    modelSet[i].Xf_com[:, 0] = (modelSet[i].Xf_com[:, 0] - av_dx)/std_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875bd2f1-ca97-4271-b2f3-899fedb5b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "wctm = cellTraj.Trajectory() # import Trajectory object \n",
    "nfeat = modelSet[indgood_models[0]].Xf.shape[1]\n",
    "Xf = np.zeros((0, nfeat))\n",
    "indtreatment = np.array([])\n",
    "indcellSet = np.array([])\n",
    "for i in indgood_models:\n",
    "    if inds_imagingSet_models[i] == 0:\n",
    "        Xf = np.append(Xf, modelSet[i].Xf, axis = 0)\n",
    "        # Indices for each model for later access using them\n",
    "        indtreatment = np.append(indtreatment, i*np.ones(modelSet[i].Xf.shape[0])) \n",
    "        indcellSet = np.append(indcellSet, modelSet[i].cells_indSet)\n",
    "\n",
    "indtreatment = indtreatment.astype(int)\n",
    "indcellSet = indcellSet.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c2094d-6e2c-4996-9197-483f67f19870",
   "metadata": {},
   "outputs": [],
   "source": [
    "varCutOff = 10\n",
    "from sklearn.decomposition import PCA #we will use the sklearn package (intended for ease of use over performance/scalability)\n",
    "pca = PCA(n_components = varCutOff) #n_components specifies the number of principal components to extract from the covariance matrix\n",
    "pca.fit(Xf) #builds the covariance matrix and \"fits\" the principal components\n",
    "Xpca = pca.transform(Xf) #transforms the data into the pca representation\n",
    "nPCs = Xpca.shape[1]\n",
    "\n",
    "wctm.Xpca = Xpca\n",
    "wctm.pca = pca\n",
    "for i in indgood_models:\n",
    "    if inds_imagingSet_models[i] == 0:\n",
    "        indsf = np.where(indtreatment == i)[0]\n",
    "        modelSet[i].Xpca = Xpca[indsf, :]\n",
    "\n",
    "indgood_models = indgood_models[np.where(inds_imagingSet_models[indgood_models] == 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a100986a-5af5-4272-87c1-92bfba4412e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = wctm\n",
    "wctm.trajl = trajl\n",
    "all_trajSet = [None]*nmodels\n",
    "for i in indgood_models:\n",
    "    modelSet[i].get_unique_trajectories()\n",
    "    all_trajSet[i] = modelSet[i].trajectories.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4645c1f-ff8a-42b2-b904-e971abc80134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-cell trajectories over the dimensionally reduced features\n",
    "Xpcat = np.zeros((0, pca.n_components_*trajl + nfeat_com*trajl))\n",
    "indtreatment_traj = np.array([])\n",
    "indstack_traj = np.array([])\n",
    "indframes_traj = np.array([])\n",
    "cellinds0_traj = np.array([])\n",
    "cellinds1_traj = np.array([])\n",
    "#cc_ratio_traj = np.array([])\n",
    "cb_ratio_traj = np.array([])\n",
    "for i in indgood_models:\n",
    "    print('building trajectory data for model {}...'.format(i))\n",
    "    modelSet[i].trajectories = all_trajSet[i].copy()\n",
    "    modelSet[i].trajl = trajl\n",
    "    modelSet[i].traj = modelSet[i].get_traj_segments(trajl)\n",
    "    data = modelSet[i].Xpca[modelSet[i].traj, :] # Store Xpca along single-cell trajectory snippets\n",
    "    datacom = modelSet[i].Xf_com[modelSet[i].traj, :]\n",
    "    data = data.reshape(modelSet[i].traj.shape[0], modelSet[i].Xpca.shape[1]*trajl)\n",
    "    datacom = datacom.reshape(modelSet[i].traj.shape[0], modelSet[i].Xf_com.shape[1]*trajl)\n",
    "    data = np.append(data, datacom, axis = 1)\n",
    "    indgood = np.where(np.sum(np.isnan(data), axis = 1) == 0)[0]\n",
    "    data = data[indgood, :]\n",
    "    modelSet[i].traj = modelSet[i].traj[indgood, :]\n",
    "    Xpcat = np.append(Xpcat, data, axis = 0)\n",
    "    indtreatment_traj = np.append(indtreatment_traj, i*np.ones(data.shape[0]))\n",
    "    indstacks = modelSet[i].cells_imgfileSet[modelSet[i].traj[:, 0]]\n",
    "    indstack_traj = np.append(indstack_traj, indstacks)\n",
    "    indframes = modelSet[i].cells_frameSet[modelSet[i].traj[:, 0]]\n",
    "    indframes_traj = np.append(indframes_traj, indframes)\n",
    "    cellinds0 = modelSet[i].traj[:, 0]\n",
    "    cellinds0_traj = np.append(cellinds0_traj, cellinds0)\n",
    "    cellinds1 = modelSet[i].traj[:, -1]\n",
    "    # cc_ratio = modelSet[i].cc_ratio[cellinds1]\n",
    "    # cc_ratio_traj = np.append(cc_ratio_traj, cc_ratio)\n",
    "    cellinds1_traj = np.append(cellinds1_traj, cellinds1)\n",
    "    cb_ratio_traj = np.append(cb_ratio_traj, modelSet[i].Xf[cellinds1, 77])\n",
    "\n",
    "cellinds0_traj = cellinds0_traj.astype(int)\n",
    "cellinds1_traj = cellinds1_traj.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e79b75e-14a1-4e15-8419-58b28b4cead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_embedding = True\n",
    "neigen_umap = 2\n",
    "if get_embedding:\n",
    "    reducer = umap.UMAP(n_neighbors=200, min_dist=0.1, n_components=neigen_umap, metric='euclidean')\n",
    "    trans = reducer.fit(Xpcat)\n",
    "    x = trans.embedding_\n",
    "    indst = np.arange(x.shape[0]).astype(int)\n",
    "    wctm.Xtraj = x.copy()\n",
    "    wctm.indst = indst.copy()\n",
    "    #dump(x, sysName+'_trajl'+str(trajl)+'_d2embedding_'+date2day+'.joblib')\n",
    "else:\n",
    "    #x=load(sysName+'_trajl'+str(trajl)+'_d2embedding_'+date2day+'.joblib')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee71d132-dad1-493d-85f2-731ff7efb637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neigen = x.shape[1]\n",
    "neigen = Xpcat.shape[1] # If embedded trajectories aren't UMAP'ed \n",
    "inds_conditions = [None]*nf\n",
    "for imf in range(nf):\n",
    "    indmodels = np.intersect1d(indgood_models, np.where(inds_tmSet_models == imf)[0])\n",
    "    indstm = np.array([])\n",
    "    for imodel in indmodels:\n",
    "        indtm = np.where(indtreatment_traj == imodel)\n",
    "        indstm = np.append(indstm, indtm)\n",
    "    inds_conditions[imf] = indstm.astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ef3a7-c20c-4949-8b93-d272230d019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Cluster single-cell trajectories of a given snippet length by using KMeans from deeptime \n",
    "from deeptime.clustering import KMeans\n",
    "n_clusters = 200\n",
    "model = KMeans(n_clusters = n_clusters,  # place 100 cluster centers\n",
    "               init_strategy = 'kmeans++',  # kmeans++ initialization strategy\n",
    "               max_iter = 0,  # don't actually perform the optimization, just place centers\n",
    "               fixed_seed = 13)\n",
    "################################ Initial clustering ###############################\n",
    "clustering = model.fit(Xpcat).fetch_model() # If embedded trajectories aren't UMAP'ed \n",
    "#clustering = model.fit(x).fetch_model()\n",
    "\n",
    "model.initial_centers = clustering.cluster_centers\n",
    "model.max_iter = 5000\n",
    "clusters = model.fit(Xpcat).fetch_model() # If embedded trajectories aren't UMAP'ed \n",
    "#clusters = model.fit(x).fetch_model()\n",
    "wctm.clusterst = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f05fb1e-34e5-45cf-b081-4a143e488e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = 50\n",
    "for i in indgood_models:\n",
    "    modelSet[i].trajectories = all_trajSet[i].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a0e54-958a-48cb-b824-0d5240e8ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory_steps(self, inds=None, traj=None, Xtraj=None,\n",
    "                         get_trajectories=True, nlag=1): #traj and Xtraj should be indexed same\n",
    "    if inds is None:\n",
    "        inds = np.arange(self.cells_indSet.size).astype(int)\n",
    "    if get_trajectories:\n",
    "        self.get_unique_trajectories(cell_inds=inds)\n",
    "    if traj is None:\n",
    "        traj = self.traj\n",
    "    if Xtraj is None:\n",
    "        x = self.Xtraj\n",
    "    else:\n",
    "        x = Xtraj\n",
    "    trajp1 = self.get_traj_segments(self.trajl + nlag)\n",
    "    # Reversed index array inds_nlag is created to keep indices every nlag steps\n",
    "    inds_nlag = np.flipud(np.arange(self.trajl + nlag - 1, -1, -nlag)).astype(int) #keep indices every nlag\n",
    "    trajp1 = trajp1[:, inds_nlag]\n",
    "    ntraj = trajp1.shape[0]\n",
    "    #neigen = x.shape[1]\n",
    "    neigen = Xpcat.shape[1]\n",
    "    x0 = np.zeros((0, neigen))\n",
    "    x1 = np.zeros((0, neigen))\n",
    "    inds_trajp1 = np.zeros((0, 2)).astype(int)\n",
    "    # Matching segments of trajectories and then appending the corresponding feature data from Xpcat to two arrays, 'x0' and 'x1'\n",
    "    for itraj in range(ntraj):\n",
    "        test0 = trajp1[itraj, 0:-1]\n",
    "        test1 = trajp1[itraj, 1:]\n",
    "        # traj[:, None] == test0[np.newaxis, :]: This expression compares each segment in 'traj' with 'test0'.\n",
    "        # The use of [:, None] and [np.newaxis, :] reshapes the arrays for broadcasting, allowing element-wise\n",
    "        # comparison between each segment in 'traj' and the segment 'test0'. \n",
    "        # .all(-1): This checks if all elements in a segment are equal, resulting in a boolean array where each\n",
    "        # element represents whether a segment in 'traj' matches 'test0'.\n",
    "        # .any(-1): This determines if there is any match in 'traj' for 'test0'. 'res0' is a boolean array indicating\n",
    "        # which trajectories in 'traj' match 'test0'\n",
    "        res0 = (traj[:, None] == test0[np.newaxis, :]).all(-1).any(-1)\n",
    "        res1 = (traj[:, None] == test1[np.newaxis, :]).all(-1).any(-1)\n",
    "        if np.sum(res0) == 1 and np.sum(res1) == 1:\n",
    "            indt0 = np.where(res0)[0][0]\n",
    "            indt1 = np.where(res1)[0][0]\n",
    "            #x0 = np.append(x0, np.array([x[indt0, :]]), axis=0)\n",
    "            #x1 = np.append(x1, np.array([x[indt1, :]]), axis=0)\n",
    "            x0 = np.append(x0, np.array([Xpcat[indt0, :]]), axis=0)\n",
    "            x1 = np.append(x1, np.array([Xpcat[indt1, :]]), axis=0)\n",
    "            inds_trajp1 = np.append(inds_trajp1, np.array([[indt0, indt1]]), axis=0)\n",
    "        if itraj%100 == 0:\n",
    "            sys.stdout.write('matching up trajectory '+str(itraj)+'\\n')\n",
    "    self.Xtraj0 = x0\n",
    "    self.Xtraj1 = x1\n",
    "    self.inds_trajp1 = inds_trajp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b398e48-a954-4ff3-bb66-2924f48ca7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dxs = np.zeros((nmodels, n_clusters, neigen))\n",
    "x0set = np.zeros((0, neigen))\n",
    "x1set = np.zeros((0, neigen))\n",
    "inds_trajsteps_models = np.array([]).astype(int)\n",
    "for i in indgood_models:\n",
    "    print('getting flows from model: '+str(i))\n",
    "    indstm = np.where(indtreatment_traj == i)[0]\n",
    "    if indstm.size > 0:\n",
    "        #modelSet[i].Xtraj = x[indstm, 0:neigen]\n",
    "        modelSet[i].Xtraj = Xpcat[indstm, 0:neigen]\n",
    "        indstm_model = indstm - np.min(indstm) #index in model\n",
    "        if inds_imagingSet_models[i] == 1:\n",
    "            modelSet[i].get_trajectory_steps(inds=None, get_trajectories=False, traj=modelSet[i].traj[indstm_model, :],\n",
    "                                             Xtraj=modelSet[i].Xtraj[indstm_model, :])\n",
    "        else:\n",
    "            get_trajectory_steps(modelSet[i], inds=None, get_trajectories=False, traj=modelSet[i].traj[indstm_model, :], \n",
    "                                 Xtraj=modelSet[i].Xtraj[indstm_model, :])\n",
    "        x0 = modelSet[i].Xtraj0\n",
    "        x1 = modelSet[i].Xtraj1\n",
    "        x0set = np.append(x0set, x0, axis=0)\n",
    "        x1set = np.append(x1set, x1, axis=0)\n",
    "        inds_trajsteps_models = np.append(inds_trajsteps_models, np.ones(x0.shape[0])*i)\n",
    "        dx = x1 - x0\n",
    "        for iclust in range(n_clusters):\n",
    "            xc = np.array([clusters.cluster_centers[iclust, :]])\n",
    "            dmatr = wctm.get_dmat(modelSet[i].Xtraj[modelSet[i].inds_trajp1[:, -1], :], xc) #get closest cells to cluster center\n",
    "            indr = np.argsort(dmatr[:, 0])\n",
    "            indr = indr[0:knn]\n",
    "            cellindsr = modelSet[i].traj[[modelSet[i].inds_trajp1[indr, -1]], -1]\n",
    "            dxs[i, iclust, :] = np.mean(dx[indr, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b37bf3-e54e-44d2-91f6-00a502667705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdist2d(prob1):\n",
    "    nx = prob1.shape[0]; ny = prob1.shape[1]\n",
    "    prob1 = prob1/np.sum(prob1)\n",
    "    prob1 = prob1.flatten()\n",
    "    indprob1 = np.argsort(prob1)\n",
    "    probc1 = np.zeros_like(prob1)\n",
    "    probc1[indprob1] = np.cumsum(prob1[indprob1])\n",
    "    probc1 = 1. - probc1\n",
    "    probc1 = probc1.reshape((nx, ny))\n",
    "    return probc1\n",
    "\n",
    "def colorbar(mappable):\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    last_axes = plt.gca()\n",
    "    ax = mappable.axes\n",
    "    fig = ax.figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = fig.colorbar(mappable, cax=cax)\n",
    "    plt.sca(last_axes)\n",
    "    return cbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e361ded-96fd-4637-a8a9-fd362aad2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indtreatment_traj = indtreatment_traj.astype(int)\n",
    "inds_imagingSet_traj = inds_imagingSet_models[indtreatment_traj]\n",
    "\n",
    "dxsav = np.mean(dxs, axis=0)\n",
    "#frames for a time window\n",
    "#fl = 0\n",
    "#fu = nframes \n",
    "fl = 72\n",
    "fu = 120\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize = (9, 9))\n",
    "indstw = np.where(np.logical_and(indframes_traj < fu, indframes_traj > fl))[0]\n",
    "indscc = np.where(cb_ratio_traj < np.inf)[0]\n",
    "indstw = np.intersect1d(indstw, indscc)\n",
    "#indstw=np.intersect1d(indstw,np.where(inds_imagingSet_traj==1)[0])\n",
    "probSet = [None]*nmodels\n",
    "nbins = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4642e78-ba7e-47f6-89b2-7ba9397399f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1,xedges1,yedges1 = np.histogram2d(x[indstw, 0], x[indstw, 1], bins=nbins, density=True)\n",
    "prob1 = prob1/np.sum(prob1)\n",
    "prob1 = scipy.ndimage.gaussian_filter(prob1, sigma=2)\n",
    "xx, yy = np.meshgrid(.5*xedges1[1:] + .5*xedges1[0:-1], .5*yedges1[1:] + .5*yedges1[0:-1])\n",
    "probSet = [None]*nf\n",
    "for imf in range(nf):\n",
    "    indstm = inds_conditions[imf]\n",
    "    indstwm = np.intersect1d(indstm,indstw)\n",
    "    prob,xedges2,yedges2 = np.histogram2d(x[indstwm, 0], x[indstwm, 1], bins=[xedges1, yedges1], density=True)\n",
    "    prob = scipy.ndimage.gaussian_filter(prob, sigma=2)\n",
    "    prob = prob/np.sum(prob)\n",
    "    probSet[imf] = prob.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ea1ee-596b-4fed-8709-5fd0ccbdcaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Generate transition matrix ############################\n",
    "centers_minima  = clusters.cluster_centers.copy()\n",
    "nclusters = clusters.cluster_centers.shape[0]\n",
    "\n",
    "# Assign \"new data\" to cluster centers\n",
    "indc0 = clusters.transform(x0set).astype(int)\n",
    "indc1 = clusters.transform(x1set).astype(int)\n",
    "wctm.get_transitionMatrixDeeptime(indc0, indc1, nclusters)\n",
    "P = wctm.Mt.copy()\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "graph = csr_matrix(P > 0.)\n",
    "n_components, labels = connected_components(csgraph=graph, directed=False, return_labels=True)\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "icc = unique[np.argmax(counts)]\n",
    "indcc = np.where(labels == icc)[0]\n",
    "centers_minima = centers_minima[indcc, :]\n",
    "\n",
    "############### Using pyEmma for assignments only #################\n",
    "import pyemma.coordinates as coor\n",
    "clusters_minima = coor.clustering.AssignCenters(centers_minima, metric='euclidean')\n",
    "#### Now clusters_minima will have attribute clusters_minima.clustercenters\n",
    "nclusters = clusters_minima.clustercenters.shape[0]\n",
    "indc0 = clusters_minima.assign(x0set)\n",
    "indc1 = clusters_minima.assign(x1set)\n",
    "wctm.get_transitionMatrixDeeptime(indc0, indc1, nclusters)\n",
    "P = wctm.Mt.copy()\n",
    "\n",
    "import pygpcca as gp\n",
    "gpcca = gp.GPCCA(P, eta=None, z='LM', method='brandts')\n",
    "\n",
    "# Dump Transition Matrix for further analysis \n",
    "tmFileName = 'tMat_'+sysName+'_'+str(trajl)+'_'+date2day+'pc'+str(nPCs)+'u'+str(neigen_umap)+wellsInfo+'.joblib'\n",
    "with open(tmFileName, 'wb') as fp:\n",
    "     dump(P, fp, compress = 'zlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7131f9d-70a2-4ed0-8711-5a684385c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Eigen Values and Eigen vectors of the transition matrix \"P\"\n",
    "H = .5*(P + np.transpose(P)) + .5j*(P - np.transpose(P))\n",
    "w, v = np.linalg.eig(H)  \n",
    "w = np.real(w)\n",
    "indsort = np.argsort(w)\n",
    "w = w[indsort] # Eigen Values\n",
    "v = v[:, indsort] # Eigen Vectors\n",
    "ncomp = n_components_tMat # Keep last \"ncomp\" eigen vectors\n",
    "vr = np.multiply(w[-ncomp:], np.real(v[:, -ncomp:]))\n",
    "vi = np.multiply(w[-ncomp:], np.imag(v[:, -ncomp:]))\n",
    "vkin = np.append(vr, vi, axis = 1)\n",
    "#plt.plot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f876c8-d956-4b97-8578-d8a85f3e24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Get kinetics of cell (macro) state transitions #####################\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_kinetic_states_module(self, vkin, nstates_final, nstates_initial = None, pcut_final = .01,\n",
    "                              max_states = 20, cluster_ninit = 10):\n",
    "       nstates_good = 0\n",
    "       nstates = nstates_initial\n",
    "       vkinFit = vkin\n",
    "       while nstates <= max_states:\n",
    "            clusters_v = KMeans(n_clusters = nstates, init = 'k-means++',\n",
    "                                n_init = cluster_ninit, max_iter = 5000, \n",
    "                                random_state = 0)\n",
    "            clusters_v.fit(vkinFit) \n",
    "            stateSet = clusters_v.labels_\n",
    "            state_probs = np.zeros(nstates)\n",
    "            statesc,counts = np.unique(stateSet, return_counts = True)\n",
    "            state_probs[statesc] = counts/np.sum(counts)\n",
    "            print(np.sort(state_probs))\n",
    "            nstates_good = np.sum(state_probs > pcut_final)\n",
    "            print('{} states initial, {} states final'.format(nstates, nstates_good))\n",
    "            print(nstates, \"Current states\", nstates_good, \"Good states\")\n",
    "            nstates = nstates + 1\n",
    "            if nstates_good >= nstates_final:\n",
    "               break\n",
    "       pcut = np.sort(state_probs)[-(nstates_final)] #nstates\n",
    "       states_plow = np.where(state_probs < pcut)[0]\n",
    "       # Assign (micro)states to existing state centers aka macrostates with probabilities less than 'pcut'\n",
    "       for i in states_plow:\n",
    "           indstate = np.where(stateSet == i)[0]\n",
    "           for imin in indstate:\n",
    "               dists = wctm.get_dmat(np.array([vkinFit[imin, :]]), vkinFit)[0] #closest in eigen space\n",
    "               dists[indstate] = np.inf\n",
    "               ireplace = np.argmin(dists)\n",
    "               stateSet[imin] = stateSet[ireplace]\n",
    "       slabels, counts = np.unique(stateSet, return_counts = True)\n",
    "       s = 0\n",
    "       stateSet_clean = np.zeros_like(stateSet)\n",
    "       for slabel in slabels:\n",
    "           indstate = np.where(stateSet == slabel)[0]\n",
    "           stateSet_clean[indstate] = s\n",
    "           s = s + 1\n",
    "       stateSet = stateSet_clean\n",
    "       if np.max(stateSet) > nstates_final:\n",
    "          print(\"returning \", np.max(stateSet),\" states\", nstates_final, \"requested\")\n",
    "       return stateSet, nstates_good  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b7542-bf9d-4afc-bf45-90a8106e423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module to optimize pcut_final that shows the best clustering onto 7 states \n",
    "def get_kinetic_states(self, vkin, nstates_final, nstates_initial = None, pcut_final = .01,\n",
    "                       max_states = 20, cluster_ninit = 10):\n",
    "       if nstates_initial is None:\n",
    "          nstates_initial = nstates_final\n",
    "       nstates_good = 0\n",
    "       while nstates_good < nstates_final or nstates_good > nstates_final:\n",
    "                 stateSet, nstates_good = get_kinetic_states_module(wctm, vkin, nstates_final, \n",
    "                                                                     nstates_initial = nstates_initial, \n",
    "                                                                     pcut_final = pcut_final,\n",
    "                                                                     max_states = max_states,\n",
    "                                                                     cluster_ninit = cluster_ninit)\n",
    "                 print(\"pcut_final = \",pcut_final)\n",
    "                 pcut_final = pcut_final - 0.001 \n",
    "\n",
    "       return stateSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2a273-f036-4d6c-9531-1772bc968431",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kstates = True\n",
    "stateCenters = clusters_minima.clustercenters\n",
    "if get_kstates:\n",
    "   stateSet = get_kinetic_states(wctm, vkin, nstates_final,\n",
    "                                 nstates_initial = None, pcut_final = pcut_final, \n",
    "                                 max_states = max_states, cluster_ninit = 10)\n",
    "   nstates = np.unique(stateSet).size\n",
    "   objFile = 'stateSet_'+figid+'_nS'+str(nstates)+'.joblib'\n",
    "   states_object = [clusters_minima, stateSet]\n",
    "   with open(objFile, 'wb') as fpStates:\n",
    "      dump(states_object, fpStates, compress = 'zlib')\n",
    "else:\n",
    "   objFile = 'stateSet_'+figid+'_nS'+str(nstates_initial)+'.joblib'\n",
    "   with open(objFile, 'rb') as fpStates:\n",
    "       states_object = load(fpStates)\n",
    "   clusters_minima = states_object[0]\n",
    "   stateSet = states_object[1]\n",
    "   nstates = np.unique(stateSet).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a176a-e25e-4f4c-835c-99e78cf2c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = nstates\n",
    "state_centers_minima = np.zeros((n_states, neigen))\n",
    "for i in range(n_states):\n",
    "    indstate = np.where(stateSet == i)[0]\n",
    "    state_centers_minima[i, :] = np.median(stateCenters[indstate, :], axis=0)\n",
    "\n",
    "state_labels = np.array(list(string.ascii_uppercase))[0:nstates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd7d78-b721-4e05-b919-f3c1e3f4306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_probs = np.zeros((nf, n_states))\n",
    "fl = 72\n",
    "fu = 120\n",
    "#fu = nframes\n",
    "cell_states = clusters_minima\n",
    "indstw = np.where(np.logical_and(indframes_traj < fu, indframes_traj > fl))[0]\n",
    "for i in range(nf):\n",
    "    indstm = inds_conditions[i]\n",
    "    indstwm = np.intersect1d(indstm, indstw)\n",
    "    #x0 = x[indstwm, :]\n",
    "    x0 = Xpcat[indstwm, :]\n",
    "    indc0 = stateSet[clusters_minima.assign(x0)]\n",
    "    statesc,counts = np.unique(indc0, return_counts=True)\n",
    "    state_probs[i, statesc] = counts/np.sum(counts)\n",
    "\n",
    "state_order = np.arange(n_states).astype(int)\n",
    "plt.clf()\n",
    "plt.imshow(state_probs[:, state_order], cmap=plt.cm.gnuplot)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('state probabilities')\n",
    "# We want to show all ticks...\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(np.arange(len(tmSet)))\n",
    "ax.set_xticks(np.arange(nstates))\n",
    "ax.set_xticklabels(np.array(state_labels)[state_order])\n",
    "ax.set_yticklabels(tmSet)\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=10, ha=\"right\",rotation_mode=\"anchor\")\n",
    "plt.pause(.1);\n",
    "\n",
    "plt.savefig('stProbs_'+figid+'_nS'+str(nstates)+'pc'+str(nPCs)+'u'+str(neigen_umap)+wellsInfo+'.png')\n",
    "np.savetxt('stProbs_'+figid+'_nS'+str(nstates)+'pc'+str(nPCs)+'u'+str(neigen_umap)+wellsInfo+'.dat', state_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Single Cell dynMorph Analysis",
   "language": "python",
   "name": "sctmd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
