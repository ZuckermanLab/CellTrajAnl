{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cc6c32e-c1ef-4bb6-8935-c4f7de89734b",
   "metadata": {},
   "source": [
    "## Feature (Engineering) Regressions using ML/DL Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672f9f73-1c5b-4023-b03d-905d9a6bc31c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 14:51:56.246355: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-06 14:51:56.260325: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-06 14:51:56.284017: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-06 14:51:56.290531: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-06 14:51:56.308428: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-06 14:52:06.576091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os, time, math\n",
    "import h5py \n",
    "sys.path.append('/home/groups/ZuckermanLab/jalim/instalLocal/celltraj/celltraj')\n",
    "import jcTrajectory_CP as cellTraj\n",
    "import pickle, subprocess\n",
    "import umap, scipy, json \n",
    "from csaps import csaps\n",
    "import string, ast \n",
    "from joblib import dump, load\n",
    "from datetime import date\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a52c36b-847b-4526-a3a3-074893cc5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix,\\\n",
    "precision_score, f1_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b0e3fb-b76b-41fc-af6c-e345a4517459",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajl = 1\n",
    "today = date.today()\n",
    "date2day = today.strftime(\"%b%d-%Y\")\n",
    "sysName = 'LI204601_P'\n",
    "figid = f\"{sysName}_{date2day}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573ebe5b-10e7-4c89-a4e1-9f014ac6416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fovs = ['A2_2']\n",
    "nfovs = len(fovs)\n",
    "pathSet = '/home/groups/ZuckermanLab/jalim/LI204601_INCUCYTE/segsCellPose/bayesianTrackTest/'\n",
    "modelList = [None]*(nfovs)\n",
    "modelList_conditions = np.zeros(nfovs).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf28618-ac83-4dda-8632-e4b99d9686d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nfovs):\n",
    "    modelList_conditions[i] = i\n",
    "    modelList[i] = f\"{pathSet}{sysName}_{fovs[i]}\"\n",
    "    #print(\"Model Info: \",modelList[i])\n",
    "\n",
    "nmodels = len(modelList)\n",
    "modelSet = [None]*nmodels\n",
    "indgood_models = np.array([]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1186e6e6-bcfe-4f25-b1fb-74693993ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded /home/groups/ZuckermanLab/jalim/LI204601_INCUCYTE/segsCellPose/bayesianTrackTest/LI204601_P_A2_2.obj with 97764 cells\n"
     ]
    }
   ],
   "source": [
    "for i in range(nmodels):\n",
    "    try:\n",
    "        objFile = modelList[i]+'.obj'\n",
    "        objFileHandler = open(objFile,'rb')\n",
    "        modelSet[i] = pickle.load(objFileHandler)\n",
    "        print(f\"loaded {objFile} with {modelSet[i].cells_indSet.size} cells\")\n",
    "        objFileHandler.close()\n",
    "        test = len(modelSet[i].linSet)\n",
    "        indgood_models = np.append(indgood_models, i)\n",
    "    except:\n",
    "        print(\"ERROR in reading *.obj files\")\n",
    "        sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cb6c82-bd37-4b87-85e0-1121406521c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 193 # Total number of frames (image snapshots) in one condition per FOVs\n",
    "cellnumber_stdSet = np.ones(nmodels)*np.inf\n",
    "# range of frame indices where cell numbers are higher: ~70-98%\n",
    "sframe = 70.*n_frames/100.; sframe = math.ceil(sframe)\n",
    "eframe = 98.5*n_frames/100.; eframe = math.ceil(eframe)\n",
    "cellnumber_frames = np.arange(sframe, eframe).astype(int)\n",
    "cellnumber_std_cut = .50 # This was set to 0.10 by Jeremy \n",
    "frames = np.arange(n_frames)\n",
    "# Abscissas at which smoothing will be done using CSAPS package\n",
    "abSmooth = np.linspace(frames[0], frames[-1], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec51aca4-8c01-491d-a585-ca8c22f84243",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indgood_models:\n",
    "    ncells = np.zeros(n_frames)\n",
    "    ncells_smooth = np.zeros_like(ncells)\n",
    "    for iS in range(n_frames):\n",
    "        ncells[iS] = np.sum(modelSet[i].cells_frameSet == iS)\n",
    "    # Cubic Spline Approximation (CSAPS) to smoothen the data\n",
    "    splfov = csaps(frames, ncells/ncells[0], abSmooth, smooth = 0.98) # Scaled by ncells[0] to avoid large numbers\n",
    "    ncells_smooth = splfov*ncells[0] # smoothened cell numbers reverse scaled back to original\n",
    "    cellnumber_std = np.std(ncells[cellnumber_frames] - ncells_smooth[cellnumber_frames])/np.mean(ncells[cellnumber_frames])\n",
    "    cellnumber_stdSet[i] = cellnumber_std # Standard Deviation in Cell Numbers\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecdaec06-322c-49db-95dd-908ee14e33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "indhigh_std = np.where(cellnumber_stdSet > cellnumber_std_cut)[0]\n",
    "indgood_models = np.setdiff1d(indgood_models, indhigh_std)\n",
    "for i in indgood_models:\n",
    "    modelSet[i].Xf[np.isnan(modelSet[i].Xf)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d04cff-6e16-4a08-ab86-c70e19880421",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_COMfeatures = 3\n",
    "Xf_com0 = np.zeros((0, n_COMfeatures))\n",
    "for i in indgood_models:\n",
    "    Xf_com0 = np.append(Xf_com0,modelSet[i].Xf_com, axis = 0)\n",
    "\n",
    "av_dx = np.nanmean(Xf_com0[:, 0])\n",
    "std_dx = np.nanstd(Xf_com0[:, 0])\n",
    "for i in indgood_models:\n",
    "    modelSet[i].Xf_com[:, 0] = (modelSet[i].Xf_com[:, 0] - av_dx)/std_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "875bd2f1-ca97-4271-b2f3-899fedb5b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "wctm = cellTraj.Trajectory() # import Trajectory object \n",
    "# Cell features: Zernike (49), Haralick (13), Shape (15), Boundary (15) --> total 92\n",
    "n_features = modelSet[indgood_models[0]].Xf.shape[1]\n",
    "Xf = np.zeros((0, n_features))\n",
    "indtreatment = np.array([])\n",
    "indcellSet = np.array([])\n",
    "\n",
    "for i in indgood_models:\n",
    "    Xf = np.append(Xf, modelSet[i].Xf, axis = 0)\n",
    "    # Indices for each model for later access using them\n",
    "    indtreatment = np.append(indtreatment, i*np.ones(modelSet[i].Xf.shape[0])) \n",
    "    indcellSet = np.append(indcellSet, modelSet[i].cells_indSet)\n",
    "\n",
    "indtreatment = indtreatment.astype(int)\n",
    "indcellSet = indcellSet.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aed0a851-2944-4692-90e8-0fc4709c69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indgood_models:\n",
    "    indsf = np.where(indtreatment == i)[0]\n",
    "    modelSet[i].Xf = Xf[indsf, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a100986a-5af5-4272-87c1-92bfba4412e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get single-cell trajectories of model: 0\n",
      "tracked cell 97681, 99 tracks, 96000 left\n",
      "tracked cell 97491, 26 tracks, 88600 left\n",
      "tracked cell 97080, 1 tracks, 70500 left\n",
      "tracked cell 97030, 1 tracks, 69600 left\n",
      "tracked cell 96323, 1 tracks, 69200 left\n",
      "tracked cell 95568, 1 tracks, 68800 left\n",
      "tracked cell 94699, 1 tracks, 68200 left\n",
      "tracked cell 94670, 3 tracks, 68100 left\n",
      "tracked cell 94178, 1 tracks, 67300 left\n",
      "tracked cell 92330, 2 tracks, 66100 left\n",
      "tracked cell 92141, 5 tracks, 65900 left\n",
      "tracked cell 92088, 1 tracks, 65800 left\n",
      "tracked cell 91522, 1 tracks, 65600 left\n",
      "tracked cell 90715, 1 tracks, 64800 left\n",
      "tracked cell 89955, 19 tracks, 63900 left\n",
      "tracked cell 88654, 1 tracks, 62700 left\n",
      "tracked cell 88173, 2 tracks, 62600 left\n",
      "tracked cell 87958, 1 tracks, 62400 left\n",
      "tracked cell 87425, 36 tracks, 61900 left\n",
      "tracked cell 86624, 1 tracks, 61200 left\n",
      "tracked cell 86238, 1 tracks, 60900 left\n",
      "tracked cell 83339, 1 tracks, 58900 left\n",
      "tracked cell 83179, 1 tracks, 58800 left\n",
      "tracked cell 82861, 1 tracks, 58500 left\n",
      "tracked cell 82420, 2 tracks, 58200 left\n",
      "tracked cell 80979, 5 tracks, 56800 left\n",
      "tracked cell 80711, 1 tracks, 56500 left\n",
      "tracked cell 79676, 1 tracks, 55600 left\n",
      "tracked cell 79418, 1 tracks, 55500 left\n",
      "tracked cell 79117, 1 tracks, 54900 left\n",
      "tracked cell 78621, 1 tracks, 54500 left\n",
      "tracked cell 77494, 1 tracks, 53800 left\n",
      "tracked cell 77121, 1 tracks, 53600 left\n",
      "tracked cell 76980, 1 tracks, 53300 left\n",
      "tracked cell 75727, 5 tracks, 52400 left\n",
      "tracked cell 74030, 1 tracks, 51100 left\n",
      "tracked cell 73214, 1 tracks, 50300 left\n",
      "tracked cell 72535, 1 tracks, 49600 left\n",
      "tracked cell 71260, 1 tracks, 48600 left\n",
      "tracked cell 71056, 22 tracks, 48400 left\n",
      "tracked cell 70671, 1 tracks, 48100 left\n",
      "tracked cell 70187, 1 tracks, 48000 left\n",
      "tracked cell 69727, 1 tracks, 47500 left\n",
      "tracked cell 68860, 1 tracks, 46900 left\n",
      "tracked cell 68264, 1 tracks, 46500 left\n",
      "tracked cell 67676, 1 tracks, 46100 left\n",
      "tracked cell 67035, 2 tracks, 45500 left\n",
      "tracked cell 66623, 1 tracks, 45000 left\n",
      "tracked cell 66298, 2 tracks, 44700 left\n",
      "tracked cell 66059, 2 tracks, 44400 left\n",
      "tracked cell 65290, 1 tracks, 44000 left\n",
      "tracked cell 64095, 1 tracks, 43200 left\n",
      "tracked cell 63545, 1 tracks, 42600 left\n",
      "tracked cell 63356, 1 tracks, 42500 left\n",
      "tracked cell 62361, 1 tracks, 41900 left\n",
      "tracked cell 61737, 1 tracks, 41600 left\n",
      "tracked cell 61331, 3 tracks, 41500 left\n",
      "tracked cell 61101, 1 tracks, 41400 left\n",
      "tracked cell 60784, 109 tracks, 41000 left\n",
      "tracked cell 60696, 25 tracks, 40800 left\n",
      "tracked cell 59762, 1 tracks, 39900 left\n",
      "tracked cell 59059, 1 tracks, 39200 left\n",
      "tracked cell 58908, 1 tracks, 39100 left\n",
      "tracked cell 56926, 1 tracks, 37700 left\n",
      "tracked cell 56639, 1 tracks, 37600 left\n",
      "tracked cell 56163, 7 tracks, 37300 left\n",
      "tracked cell 56007, 1 tracks, 37200 left\n",
      "tracked cell 55234, 84 tracks, 36500 left\n",
      "tracked cell 54259, 1 tracks, 36100 left\n",
      "tracked cell 53797, 1 tracks, 35500 left\n",
      "tracked cell 53423, 1 tracks, 35300 left\n",
      "tracked cell 53081, 3 tracks, 35100 left\n",
      "tracked cell 51653, 1 tracks, 34400 left\n",
      "tracked cell 50068, 1 tracks, 32800 left\n",
      "tracked cell 48424, 1 tracks, 31400 left\n",
      "tracked cell 48021, 1 tracks, 30800 left\n",
      "tracked cell 47039, 1 tracks, 30300 left\n",
      "tracked cell 46643, 89 tracks, 29900 left\n",
      "tracked cell 45311, 1 tracks, 29000 left\n",
      "tracked cell 44820, 1 tracks, 28800 left\n",
      "tracked cell 43731, 1 tracks, 28200 left\n",
      "tracked cell 42761, 1 tracks, 27000 left\n",
      "tracked cell 41737, 1 tracks, 26100 left\n",
      "tracked cell 41417, 1 tracks, 26000 left\n",
      "tracked cell 41225, 1 tracks, 25800 left\n",
      "tracked cell 41058, 3 tracks, 25600 left\n",
      "tracked cell 40905, 1 tracks, 25400 left\n",
      "tracked cell 40794, 1 tracks, 25200 left\n",
      "tracked cell 37548, 1 tracks, 22600 left\n",
      "tracked cell 37277, 1 tracks, 22500 left\n",
      "tracked cell 35989, 1 tracks, 21800 left\n",
      "tracked cell 35839, 1 tracks, 21700 left\n",
      "tracked cell 34620, 15 tracks, 20700 left\n",
      "tracked cell 34455, 1 tracks, 20600 left\n",
      "tracked cell 33974, 2 tracks, 20300 left\n",
      "tracked cell 33006, 1 tracks, 19600 left\n",
      "tracked cell 32665, 1 tracks, 19400 left\n",
      "tracked cell 32540, 1 tracks, 19300 left\n",
      "tracked cell 29825, 1 tracks, 17600 left\n",
      "tracked cell 29658, 1 tracks, 17500 left\n",
      "tracked cell 29254, 1 tracks, 17400 left\n",
      "tracked cell 28927, 1 tracks, 17300 left\n",
      "tracked cell 28659, 11 tracks, 17200 left\n",
      "tracked cell 28191, 1 tracks, 17000 left\n",
      "tracked cell 27113, 1 tracks, 16300 left\n",
      "tracked cell 26845, 1 tracks, 16200 left\n",
      "tracked cell 26684, 1 tracks, 16000 left\n",
      "tracked cell 26345, 12 tracks, 15800 left\n",
      "tracked cell 24931, 1 tracks, 14800 left\n",
      "tracked cell 24608, 1 tracks, 14500 left\n",
      "tracked cell 22812, 1 tracks, 13300 left\n",
      "tracked cell 22631, 1 tracks, 13200 left\n",
      "tracked cell 21092, 1 tracks, 12100 left\n",
      "tracked cell 19166, 1 tracks, 10900 left\n",
      "tracked cell 18999, 1 tracks, 10800 left\n",
      "tracked cell 18638, 1 tracks, 10600 left\n",
      "tracked cell 18348, 1 tracks, 10400 left\n",
      "tracked cell 17373, 1 tracks, 10000 left\n",
      "tracked cell 16958, 1 tracks, 9800 left\n",
      "tracked cell 16729, 4 tracks, 9700 left\n",
      "tracked cell 16140, 1 tracks, 9500 left\n",
      "tracked cell 14944, 3 tracks, 8900 left\n",
      "tracked cell 14639, 1 tracks, 8800 left\n",
      "tracked cell 14264, 2 tracks, 8700 left\n",
      "tracked cell 13710, 1 tracks, 8500 left\n",
      "tracked cell 13132, 1 tracks, 8300 left\n",
      "tracked cell 11401, 1 tracks, 7500 left\n",
      "tracked cell 11018, 1 tracks, 7300 left\n",
      "tracked cell 10055, 1 tracks, 7000 left\n",
      "tracked cell 9779, 3 tracks, 6900 left\n",
      "tracked cell 9425, 1 tracks, 6800 left\n",
      "tracked cell 9199, 1 tracks, 6700 left\n",
      "tracked cell 9001, 2 tracks, 6600 left\n",
      "tracked cell 8524, 17 tracks, 6500 left\n",
      "tracked cell 8075, 1 tracks, 6400 left\n",
      "tracked cell 7825, 1 tracks, 6300 left\n",
      "tracked cell 7348, 18 tracks, 5700 left\n",
      "tracked cell 7226, 11 tracks, 4900 left\n",
      "tracked cell 7084, 1 tracks, 4100 left\n",
      "tracked cell 6728, 1 tracks, 4000 left\n",
      "tracked cell 6367, 1 tracks, 3900 left\n",
      "tracked cell 6006, 1 tracks, 3800 left\n",
      "tracked cell 5606, 1 tracks, 3700 left\n",
      "tracked cell 5163, 1 tracks, 3600 left\n",
      "tracked cell 4812, 1 tracks, 3500 left\n",
      "tracked cell 4440, 1 tracks, 3400 left\n",
      "tracked cell 4133, 1 tracks, 3300 left\n",
      "tracked cell 3709, 6 tracks, 3100 left\n",
      "tracked cell 3618, 2 tracks, 2700 left\n",
      "tracked cell 3377, 5 tracks, 1900 left\n",
      "tracked cell 3038, 1 tracks, 1800 left\n",
      "tracked cell 2020, 1 tracks, 1500 left\n",
      "tracked cell 1462, 1 tracks, 1300 left\n",
      "tracked cell 1286, 1 tracks, 1100 left\n",
      "tracked cell 1213, 1 tracks, 1000 left\n",
      "tracked cell 983, 3 tracks, 600 left\n",
      "tracked cell 837, 3 tracks, 300 left\n",
      "tracked cell 795, 3 tracks, 200 left\n",
      "tracked cell 754, 3 tracks, 100 left\n",
      "tracked cell 16, 1 tracks, 0 left\n"
     ]
    }
   ],
   "source": [
    "self = wctm\n",
    "all_trajSet = [None]*nmodels\n",
    "for i in indgood_models:\n",
    "    print(f\"Get single-cell trajectories of model: {i}\")\n",
    "    modelSet[i].get_unique_trajectories()\n",
    "    all_trajSet[i] = modelSet[i].trajectories.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23cfb7a-fba5-4cb6-80a9-be0ecc241d4d",
   "metadata": {},
   "source": [
    "## Load Cell Features & Labels Extracted from O2VAE (https://github.com/directysj/o2vae.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c52e676-f26a-43d8-8611-337bfd9afbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_latent_dim=256\n",
    "data_vae = np.load(f'../o2vae/features_vae{num_latent_dim}_LI204601_A2_2.npz')\n",
    "features_vae = data_vae['embeddings']\n",
    "labels_vae = data_vae['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b557db2a-ba45-4ee8-9626-e984d649bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indgood_models:\n",
    "    indsf = np.where(indtreatment == i)[0]\n",
    "    modelSet[i].Xf_vae = features_vae[indsf, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc146c1d-b564-4006-afaf-36f94e9260b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indgood_models:\n",
    "    cell2cell_interaction_features = modelSet[i].Xf[:, 77:]\n",
    "    modelSet[i].Xf_new = np.concatenate((modelSet[i].Xf_vae, cell2cell_interaction_features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f02430f-8987-4fa7-8d87-de31aa7526cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get snippets along with their full single-cell trajectory indices  \n",
    "def get_snippets_with_traj_inds(self, seg_length): \n",
    "    n_sctraj = len(self.trajectories) # Number of Single-Cell Trajectories \n",
    "    traj_segSet = np.zeros((0, seg_length)).astype(int)\n",
    "    ind_map_snippet_fulltraj = np.array([])\n",
    "    for ind_traj in range(n_sctraj):\n",
    "        cell_traj = self.trajectories[ind_traj] # Select a single-cell trajectory\n",
    "        traj_len = cell_traj.size\n",
    "        #print(\"Length of a Single-Cell Trajectory:\",traj_len)\n",
    "        if traj_len >= seg_length:\n",
    "            for ic in range(traj_len - seg_length):\n",
    "                traj_seg = cell_traj[ic:ic+seg_length]\n",
    "                traj_segSet = np.append(traj_segSet, traj_seg[np.newaxis, :], axis = 0)\n",
    "                # Save indices of all snippets corresponding to \"FULL\" single-cell trajectory \n",
    "                ind_map_snippet_fulltraj = np.append(ind_map_snippet_fulltraj, ind_traj)\n",
    "                #print(\"Indices to map snippets to the full trajectory:\",ind_map_snippet_fulltraj)\n",
    "    return ind_map_snippet_fulltraj, traj_segSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d128f4fe-6fe3-4931-84e2-15eab247b617",
   "metadata": {},
   "source": [
    "## Single-cell Trajectories Over The Cell Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd8ec5cf-aa27-48f3-b1e2-6bb492d0b7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building trajectory data for model: 0\n"
     ]
    }
   ],
   "source": [
    "#Xf_traj = np.zeros((0, (modelSet[0].Xf.shape[1]+n_COMfeatures)*trajl))\n",
    "#Xf_traj = np.zeros((0, (modelSet[0].Xf_new.shape[1]+n_COMfeatures)*trajl))\n",
    "Xf_traj = np.zeros((0, modelSet[0].Xf_vae.shape[1]*trajl))\n",
    "indtreatment_traj = np.array([])\n",
    "indstack_traj = np.array([])\n",
    "indframes_traj = np.array([])\n",
    "indmodel_traj_snippets = np.array([])\n",
    "for i in indgood_models:\n",
    "    print(f'Building trajectory data for model: {i}')\n",
    "    modelSet[i].trajectories = all_trajSet[i].copy() # ALL Single-Cell trajectories \n",
    "    modelSet[i].trajl = trajl # Trajectory snippet length \n",
    "    # Get trajectory snippets of (all trajectories) a given length in a sliding window and mapped with single-cell trajectory indices \n",
    "    modelSet[i].snippet_map_fulltraj_inds, modelSet[i].traj = get_snippets_with_traj_inds(modelSet[i], trajl)\n",
    "    # Xpca (feature info) along the single-cell trajectory snippets, extracted directly from cell indices unique within a 'model' \n",
    "    data = modelSet[i].Xf_vae[modelSet[i].traj, :] \n",
    "    #data = modelSet[i].Xf_new[modelSet[i].traj, :]\n",
    "    #datacom = modelSet[i].Xf_com[modelSet[i].traj, :]\n",
    "    data = data.reshape(modelSet[i].traj.shape[0], modelSet[i].Xf_vae.shape[1]*trajl)\n",
    "    #data = data.reshape(modelSet[i].traj.shape[0], modelSet[i].Xf_new.shape[1]*trajl)\n",
    "    #datacom = datacom.reshape(modelSet[i].traj.shape[0], modelSet[i].Xf_com.shape[1]*trajl)\n",
    "    #data = np.append(data, datacom, axis = 1)\n",
    "    indgood = np.where(np.sum(np.isnan(data), axis = 1) == 0)[0] # Consider models as \"Good\" that don't have NaN in \"data\" \n",
    "    data = data[indgood, :]\n",
    "    modelSet[i].traj = modelSet[i].traj[indgood, :] # Cleaned trajectory snippets if any NaN \n",
    "    modelSet[i].snippet_map_fulltraj_inds = modelSet[i].snippet_map_fulltraj_inds[indgood]\n",
    "    # Store all trajectory snippets of a given length (picked in a sliding window) \n",
    "    Xf_traj = np.append(Xf_traj, data, axis = 0) \n",
    "    indtreatment_traj = np.append(indtreatment_traj, i*np.ones(data.shape[0])) # Indices of Treatments (Models) Along Trajectory Snippets \n",
    "    indstacks = modelSet[i].cells_imgfileSet[modelSet[i].traj[:, 0]]\n",
    "    indstack_traj = np.append(indstack_traj, indstacks)\n",
    "    ind_frames = modelSet[i].cells_frameSet[modelSet[i].traj[:, 0]].astype(int) # Frame indices at the start of snippets\n",
    "    ind_frames = ind_frames + trajl # Frame indices at the end of snippets\n",
    "    indframes_traj = np.append(indframes_traj, ind_frames) # Starting Frame Indices of ALL snippets\n",
    "    indtraj_snippets = modelSet[i].snippet_map_fulltraj_inds\n",
    "    indmodel_traj_snippets = np.append(indmodel_traj_snippets, indtraj_snippets) # Save for all models: map of snippets to the sc trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "580b076d-26ef-490d-a3f0-c6954ddafeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cellCycInfoTrajs(file_info):\n",
    "    with open(file_info, 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "\n",
    "    nuc2cytoRatio = []\n",
    "    CC_vals = []\n",
    "    frames = []\n",
    "\n",
    "    for line1, line2, line3 in zip(lines[::3], lines[1::3], lines[2::3]):\n",
    "        line1 = np.array(line1.strip()[1:-1].split(', '), dtype=float)\n",
    "        line2 = np.array(line2.strip()[1:-1].split(', '), dtype=float)\n",
    "        line3 = np.array(line3.strip()[1:-1].split(', '), dtype=int)\n",
    "\n",
    "        mask = ~np.isnan(line1)\n",
    "        line1 = line1[mask]\n",
    "        line2 = line2[mask]\n",
    "        line3 = line3[mask]\n",
    "\n",
    "        nuc2cytoRatio.append(line1)\n",
    "        CC_vals.append(line2)\n",
    "        frames.append(line3)\n",
    "\n",
    "    return nuc2cytoRatio, CC_vals, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dafb8a77-651c-4201-bd79-cd984e44cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/groups/ZuckermanLab/jalim/LI204601_INCUCYTE/cellCycInfoRawReporterImgs/'\n",
    "sname_reporter = \"LI204601_G\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995898ae-1eae-4b43-8e8c-3b9e9a2f02db",
   "metadata": {},
   "source": [
    "## Get Nuc/Cyto Ratios and CC values along all single-cell trajectories  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89205262-a33c-4158-9e00-98bcbe13189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_filename = f\"{file_path}{sname_reporter}_{fovs[0]}.dat\"\n",
    "n2c_ratio, cc_vals, frame_numbers = get_cellCycInfoTrajs(cc_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47f10a71-87bb-46b5-8a7d-7995692c9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indstm = []\n",
    "nuc2Cyto_ratio_last_frames = []\n",
    "model_indc = 0\n",
    "indstm = np.where(indtreatment_traj == model_indc)[0]\n",
    "fid_snippets = indframes_traj[indstm].astype(int) # Map frame indices of snippets\n",
    "indc_map_fulltraj_snippets = indmodel_traj_snippets[indstm].astype(int) # Map Indices of Full Trajectory to Snippets \n",
    "\n",
    "for j, ind_fulltraj in enumerate(indc_map_fulltraj_snippets):\n",
    "    # Look for a snippet frame within its full trajectory\n",
    "    possible_indices = np.where(frame_numbers[ind_fulltraj] == fid_snippets[j])[0]\n",
    "    if len(possible_indices) > 0:\n",
    "        nbc_ratio = n2c_ratio[ind_fulltraj][possible_indices[0]]\n",
    "        nuc2Cyto_ratio_last_frames.append(nbc_ratio)\n",
    "        valid_indstm.append(indstm[j]) \n",
    "\n",
    "nuc2Cyto_ratio_last_frames = np.array(nuc2Cyto_ratio_last_frames)\n",
    "X = Xf_traj[valid_indstm]  # Use the valid indices to index into Xf_traj\n",
    "y = nuc2Cyto_ratio_last_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "102eebcc-9506-4311-87a4-12260403397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_cc_vals(cc_values, num_bins, target_density):\n",
    "    df = pd.DataFrame(cc_values, columns=['CC'])\n",
    "    df['original_index'] = df.index # Include original indices in the DataFrame\n",
    "    \n",
    "    counts, bin_edges = np.histogram(df['CC'], bins=num_bins) # Calculate histogram without plotting\n",
    "    df['bin'] = pd.cut(df['CC'], bins=bin_edges, labels=False, include_lowest=True) # Create a bin label based on the bin_edges\n",
    "\n",
    "    trimmed_data = []\n",
    "    \n",
    "    for i in range(num_bins):\n",
    "        bin_filter = (df['bin'] == i) # Filter the DataFrame to get data only in this bin\n",
    "        bin_data = df[bin_filter]\n",
    "\n",
    "        # If the number of items in the bin is greater than target_density, sample down\n",
    "        if bin_data.shape[0] > target_density:\n",
    "           sampled_data = bin_data.sample(n=target_density, random_state=42)\n",
    "        else:\n",
    "           sampled_data = bin_data\n",
    "        trimmed_data.append(sampled_data) # Append the sampled or full bin data to the list\n",
    "    \n",
    "    trimmed_df = pd.concat(trimmed_data) # Concatenate all trimmed data back into a DataFrame\n",
    "    trimmed_df = trimmed_df.sort_values('original_index') # Sorting by original index to preserve the original data order\n",
    "    \n",
    "    return trimmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67a67fd3-4976-4773-872e-80a77a8d11fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def unique_predictive_features(n_top_cont_features = 5):\n",
    "    loadings = pca.components_\n",
    "    feature_inds = np.array([]).astype(int)\n",
    "    for i, pc in enumerate(loadings):\n",
    "        # Gets indices of the top features for each PC\n",
    "        top_features_indices = np.argsort(np.abs(pc))[-n_top_cont_features:] \n",
    "        #print(f\"Top {n_cf} contributing feature indices for PC{i+1}: {top_features_indices}\")\n",
    "        feature_inds = np.append(feature_inds, top_features_indices)\n",
    "    unique_feature_inds = np.unique(feature_inds)\n",
    "\n",
    "    return unique_feature_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3cb63a78-2c6b-4db2-a3a5-baad473c52fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Reshape,\\\n",
    "Dense, Input, Dropout, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, KMeansSMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33754d0a-4b2a-4f34-a53f-b19029fbe1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pca = False\n",
    "if use_pca:\n",
    "    dim_reduction = False\n",
    "    if dim_reduction:\n",
    "        ############### Dimensional reduction on trimmed training data ###############\n",
    "        pca_nn.fit(X_train_trim) \n",
    "        Xpca_train_nn = pca_nn.transform(X_train_trim)\n",
    "        Xpca_test_nn = pca_nn.transform(X_test)\n",
    "    else: \n",
    "        # Select features accroding to their predictive performance \n",
    "        top_contFeat_pc = 2 # Number of top contributing features in each PC\n",
    "        #indc_predictive_features = unique_predictive_features(n_top_cont_features = top_contFeat_pc)\n",
    "        indc_predictive_features = np.array([25, 31, 36, 42, 43, 55, 62, 77, 78, 92, 93, 94]).astype(int)\n",
    "        print(f\"Indices of top predictive features: {indc_predictive_features}\") if i == 0 else None\n",
    "        Xpca_train_nn = X_train_trim[:, indc_predictive_features]\n",
    "        Xpca_test_nn = X_test[:, indc_predictive_features]\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d72134d-2a68-4bd7-b740-f9ac573c28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_nn = MinMaxScaler() # Scale features in the range [0, 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "target_density = 1000; n_bins = 50\n",
    "############################ Trim Training Data ############################ \n",
    "trimmed_cc_train = trim_cc_vals(y_train, n_bins, target_density)\n",
    "original_indices_train = []\n",
    "y_train_trim = []\n",
    "    \n",
    "for it in range(trimmed_cc_train['original_index'].shape[0]):\n",
    "    original_indices_train.append(trimmed_cc_train['original_index'].iloc[it])\n",
    "    y_train_trim.append(trimmed_cc_train['CC'].iloc[it])\n",
    "    \n",
    "original_indices_train = np.array(original_indices_train)\n",
    "y_train_trim = np.array(y_train_trim)\n",
    "X_train_trim = X_train[original_indices_train, :]\n",
    "X_train_nn = scaler_nn.fit_transform(X_train_trim)\n",
    "X_test_nn = scaler_nn.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "161354f5-2ef1-4b43-be8d-0c53ff921cc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 15.9584 - mean_absolute_error: 1.5982 - val_loss: 2.8552 - val_mean_absolute_error: 1.4209\n",
      "Epoch 2/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 2.2888 - mean_absolute_error: 1.1531 - val_loss: 0.2203 - val_mean_absolute_error: 0.2960\n",
      "Epoch 3/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.2661 - mean_absolute_error: 0.3707 - val_loss: 0.1671 - val_mean_absolute_error: 0.2914\n",
      "Epoch 4/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.2369 - mean_absolute_error: 0.3702 - val_loss: 0.1512 - val_mean_absolute_error: 0.2740\n",
      "Epoch 5/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.2314 - mean_absolute_error: 0.3667 - val_loss: 0.1675 - val_mean_absolute_error: 0.3010\n",
      "Epoch 6/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 0.2278 - mean_absolute_error: 0.3657 - val_loss: 0.1594 - val_mean_absolute_error: 0.2885\n",
      "Epoch 7/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 20ms/step - loss: 0.2268 - mean_absolute_error: 0.3653 - val_loss: 0.1587 - val_mean_absolute_error: 0.2877\n",
      "Epoch 8/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - loss: 0.2288 - mean_absolute_error: 0.3668 - val_loss: 0.1558 - val_mean_absolute_error: 0.2825\n",
      "Epoch 9/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 30ms/step - loss: 0.2269 - mean_absolute_error: 0.3649 - val_loss: 0.1640 - val_mean_absolute_error: 0.2959\n",
      "Epoch 10/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 29ms/step - loss: 0.2243 - mean_absolute_error: 0.3631 - val_loss: 0.1593 - val_mean_absolute_error: 0.2883\n",
      "Epoch 11/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - loss: 0.2285 - mean_absolute_error: 0.3658 - val_loss: 0.1588 - val_mean_absolute_error: 0.2869\n",
      "Epoch 12/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - loss: 0.2281 - mean_absolute_error: 0.3643 - val_loss: 0.1549 - val_mean_absolute_error: 0.2789\n",
      "Epoch 13/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.2243 - mean_absolute_error: 0.3612 - val_loss: 0.1551 - val_mean_absolute_error: 0.2807\n",
      "Epoch 14/50\n",
      "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 0.2256 - mean_absolute_error: 0.3641 - val_loss: 0.1742 - val_mean_absolute_error: 0.3085\n"
     ]
    }
   ],
   "source": [
    "# Bin continuous target variables into discrete categories\n",
    "kbd = KBinsDiscretizer(n_bins=3, encode='ordinal')\n",
    "y_train_class = kbd.fit_transform(y_train_trim.reshape(-1, 1))\n",
    "\n",
    "# Define RandomOverSampler to handle minority classes\n",
    "over_sampler = RandomOverSampler(random_state=42, sampling_strategy='not majority')\n",
    "\n",
    "# Apply RandomOverSampler to training data\n",
    "X_train_nn_res, y_train_class_res = over_sampler.fit_resample(X_train_nn, y_train_class)\n",
    "\n",
    "# Define the Random Forest model for classification\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train Random Forest model for classification\n",
    "rf_model.fit(X_train_nn_res, y_train_class_res.ravel())  # Flatten y_train_class_res to a 1D array\n",
    "\n",
    "# Predict class labels for training data using the Random Forest model\n",
    "y_train_rf = rf_model.predict(X_train_nn_res)\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y_train_rf_ohe = ohe.fit_transform(y_train_rf.reshape(-1, 1))\n",
    "\n",
    "# Concatenate one-hot encoded class labels with original features\n",
    "X_train_nn_rf = np.concatenate((X_train_nn_res, y_train_rf_ohe.toarray()), axis=1)\n",
    "\n",
    "# Define the CNN+DNN model for regression\n",
    "model_cdnn = Sequential([Input(shape=(X_train_nn_rf.shape[1], )),  # Input shape for the model (feature vector)\n",
    "                       Reshape((X_train_nn_rf.shape[1], 1, 1)),  # Reshape to fit Conv2D layer requirements\n",
    "                       Conv2D(32, kernel_size=(3, 1), padding='same', kernel_regularizer=l2(0.01)), # First CNN layer\n",
    "                       LeakyReLU(),\n",
    "                       BatchNormalization(), # Batch normalization\n",
    "                       MaxPooling2D(pool_size=(2, 1)),\n",
    "                       Dropout(0.2), # Dropout\n",
    "                       Conv2D(64, kernel_size=(3, 1), padding='same', kernel_regularizer=l1(0.02)), # Second CNN layer\n",
    "                       LeakyReLU(),\n",
    "                       BatchNormalization(), # Batch normalization\n",
    "                       MaxPooling2D(pool_size=(2, 1)),\n",
    "                       Dropout(0.2), # Dropout\n",
    "                       Flatten(), # Flatten the output of the last CNN layer to feed into the First dense layer\n",
    "                       Dense(128, kernel_regularizer=l2(0.01)),  # First Dense layer\n",
    "                       LeakyReLU(),\n",
    "                       Dropout(0.2), # Dropout\n",
    "                       Dense(64, kernel_regularizer=l1(0.02)), # Second Dense layer\n",
    "                       LeakyReLU(),\n",
    "                       Dropout(0.2), # Dropout\n",
    "                       Dense(1, activation='relu')  # Final dense layer with a single neuron\n",
    "                       ])\n",
    "\n",
    "model_cdnn.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                 loss='mean_squared_error',\n",
    "                 metrics=['mean_absolute_error'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                               restore_best_weights=True,\n",
    "                               patience=10)\n",
    "\n",
    "# Predict class labels for testing data using the Random Forest model\n",
    "y_test_rf = rf_model.predict(X_test_nn)\n",
    "\n",
    "# One-hot encode predicted class labels\n",
    "y_test_rf_ohe = ohe.transform(y_test_rf.reshape(-1, 1))\n",
    "\n",
    "# Concatenate one-hot encoded class labels with original features\n",
    "X_test_nn_rf = np.concatenate((X_test_nn, y_test_rf_ohe.toarray()), axis=1)\n",
    "\n",
    "# Train CNN+DNN model for regression\n",
    "history_cdnn = model_cdnn.fit(X_train_nn_rf, \n",
    "                              np.repeat(y_train_trim, 2).ravel()[:X_train_nn_rf.shape[0]],  # Repeat and flatten y_train_trim to match resampled data\n",
    "                              epochs=50, \n",
    "                              batch_size=20, \n",
    "                              validation_data=(X_test_nn_rf, y_test.ravel()),  # Flatten y_test to a 1D array\n",
    "                              callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21148374-3e70-4821-825e-57dc80d0ab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1553 - mean_absolute_error: 0.2784\n",
      "CNN+DNN Regression MSE: [0.15671153366565704, 0.2795971632003784]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the CNN+DNN model\n",
    "print(\"CNN+DNN Regression MSE:\", model_cdnn.evaluate(X_test_nn_rf, y_test.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c65dd15-81fb-47ba-a658-5146cce85620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn = model_cdnn.predict(X_test_nn_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "283b86d1-6255-46e6-8baa-55bb4e188686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAH8CAYAAADmNGq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqP0lEQVR4nO3df1BV94H38c8B9MJWuUhWzAVRUmuIYqWMbiJq3BhSU3Ru6oydxJgqa3a3WWsSV8ZuodG6NlUStdYmjtnR1TAWm+QZr7jOalJMI6FJbPOQhSZN1h9EGilCTR4jVzC5KJznD9ezXgHDEb5cNO/XzJnx3PPre86cwHsOJ2DZtm0LAAAARkRFegAAAAA3MmILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAoBi3G1RUVGjdunV655131NDQoNLSUs2ePfuq24RCIf3kJz9RSUmJGhsbNXz4cD3xxBN6+OGHJUlbt27Vjh079Mc//lGSNGHCBK1Zs0a33357t8fV3t6ukydPavDgwbIsy+1pAQAAdJtt2zp79qySk5MVFXX1Z1euY6ulpUWZmZlauHCh5syZ061t7r//fv3lL3/Rtm3b9LWvfU2nTp3ShQsXnOXl5eV68MEHNXnyZMXGxmrt2rWaMWOG3n//faWkpHTrGCdPnlRqaqrb0wEAALhmdXV1Gj58+FXXsXryh6gty/rCJ1uvvPKK5s6dq+PHjysxMbFb+21ra9OQIUO0adMmLViwoFvbNDU1KSEhQXV1dYqPj+/WNgAAANciGAwqNTVVZ86ckdfrveq6rp9subV3715NnDhRa9eu1S9/+Ut95Stf0X333acnn3xScXFxnW5z7tw5nT9//qpxFgqFFAqFnPmzZ89KkuLj44ktAADQJ7rz6pLx2Dp+/LjeeOMNxcbGqrS0VJ988om+//3v6/Tp09q+fXun2xQUFCglJUX33HNPl/stKirSqlWrTA0bAACgVxj/vxHb29tlWZZ27typ22+/XTNnztSGDRtUXFyszz77rMP6a9eu1QsvvKDdu3crNja2y/0WFhaqqanJmerq6kyeBgAAwDUx/mTL5/MpJSUl7OeZY8aMkW3b+vOf/6zRo0c7n69fv15r1qzRq6++qvHjx191vx6PRx6Px9i4AQAAeoPxJ1tTpkzRyZMn1dzc7Hx29OhRRUVFhb29v27dOj355JN65ZVXNHHiRNPDAgAA6BOuY6u5uVnV1dWqrq6WJNXW1qq6ulonTpyQdPHHe5f/H4Tz5s3TTTfdpIULF+qDDz5QRUWFfvCDH+jhhx92XpBfu3atli9fru3btystLU2NjY1qbGwMCzQAAIDrkevYqqysVFZWlrKysiRJ+fn5ysrK0o9//GNJUkNDgxNekjRo0CAdOHBAZ86c0cSJE/XQQw/J7/frmWeecdbZvHmzWltb9Z3vfEc+n8+Z1q9f39PzAwAAiKge/Z6t/iQYDMrr9aqpqYlf/QAAAIxy0x38bUQAAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDiC0AAACDXMdWRUWF/H6/kpOTZVmW9uzZ84XbhEIhPfHEExo5cqQ8Ho9GjRql7du3h60TCAQ0duxYeTwejR07VqWlpW6HBgAA0O+4jq2WlhZlZmZq06ZN3d7m/vvv129+8xtt27ZNR44c0QsvvKDbbrvNWX7o0CE98MADmj9/vv7whz9o/vz5uv/++/X73//e7fAAAAD6Fcu2bfuaN7YslZaWavbs2V2u88orr2ju3Lk6fvy4EhMTO13ngQceUDAY1Msvv+x89q1vfUtDhgzRCy+80K2xBINBeb1eNTU1KT4+3tV5AAAAuOGmO4y/s7V3715NnDhRa9euVUpKim699VYtW7ZMn332mbPOoUOHNGPGjLDt7r33Xr311ltd7jcUCikYDIZNAAAA/U2M6QMcP35cb7zxhmJjY1VaWqpPPvlE3//+93X69Gnnva3GxkYNGzYsbLthw4apsbGxy/0WFRVp1apVRscOAADQU8afbLW3t8uyLO3cuVO33367Zs6cqQ0bNqi4uDjs6ZZlWWHb2bbd4bPLFRYWqqmpyZnq6uqMnQMAAMC1Mv5ky+fzKSUlRV6v1/lszJgxsm1bf/7znzV69GjdfPPNHZ5inTp1qsPTrst5PB55PB5j4wYAAOgNxp9sTZkyRSdPnlRzc7Pz2dGjRxUVFaXhw4dLkrKzs3XgwIGw7crKyjR58mTTwwMAADDKdWw1Nzerurpa1dXVkqTa2lpVV1frxIkTki7+eG/BggXO+vPmzdNNN92khQsX6oMPPlBFRYV+8IMf6OGHH1ZcXJwkacmSJSorK9PTTz+tw4cP6+mnn9arr76qf/7nf+75GQIAAESQ69iqrKxUVlaWsrKyJEn5+fnKysrSj3/8Y0lSQ0ODE16SNGjQIB04cEBnzpzRxIkT9dBDD8nv9+uZZ55x1pk8ebJefPFFPf/88xo/fryKi4v10ksv6Y477ujp+QEAAERUj37PVn/C79kCAAB9pV/9ni0AAIAvM2ILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAIGILAADAINexVVFRIb/fr+TkZFmWpT179lx1/fLyclmW1WE6fPhw2HobN25Uenq64uLilJqaqqVLl+rzzz93OzwAAIB+JcbtBi0tLcrMzNTChQs1Z86cbm935MgRxcfHO/NDhw51/r1z504VFBRo+/btmjx5so4ePaq/+7u/kyT9/Oc/dztEAACAfsN1bOXm5io3N9f1gZKSkpSQkNDpskOHDmnKlCmaN2+eJCktLU0PPvig3n77bdfHAQAA6E/67J2trKws+Xw+5eTk6ODBg2HLpk6dqnfeeceJq+PHj2v//v2aNWtWl/sLhUIKBoNhEwAAQH/j+smWWz6fT1u2bNGECRMUCoX0y1/+Ujk5OSovL9e0adMkSXPnztXHH3+sqVOnyrZtXbhwQYsWLVJBQUGX+y0qKtKqVatMDx8AAKBHLNu27Wve2LJUWlqq2bNnu9rO7/fLsizt3btX0sWX6OfOnauf/vSnuuOOO1RTU6MlS5boH//xH7VixYpO9xEKhRQKhZz5YDCo1NRUNTU1hb0bBgAA0NuCwaC8Xm+3usP4k63OTJo0SSUlJc78ihUrNH/+fP3DP/yDJOnrX/+6Wlpa9L3vfU9PPPGEoqI6/rTT4/HI4/H02ZgBAACuRUR+z1ZVVZV8Pp8zf+7cuQ5BFR0dLdu21YMHbwAAABHn+slWc3OzampqnPna2lpVV1crMTFRI0aMUGFhoerr67Vjxw5JF39/VlpamjIyMtTa2qqSkhIFAgEFAgFnH36/Xxs2bFBWVpbzY8QVK1bovvvuU3R0dC+cJgAAQGS4jq3KykpNnz7dmc/Pz5ck5eXlqbi4WA0NDTpx4oSzvLW1VcuWLVN9fb3i4uKUkZGhffv2aebMmc46y5cvl2VZWr58uerr6zV06FD5/X6tXr26J+cGAAAQcT16Qb4/cfOiGgAAQE+46Q7+NiIAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBrmOroqJCfr9fycnJsixLe/bsuer65eXlsiyrw3T48OGw9c6cOaPFixfL5/MpNjZWY8aM0f79+90ODwAAoF+JcbtBS0uLMjMztXDhQs2ZM6fb2x05ckTx8fHO/NChQ51/t7a26pvf/KaSkpK0a9cuDR8+XHV1dRo8eLDb4QEAAPQrrmMrNzdXubm5rg+UlJSkhISETpdt375dp0+f1ltvvaUBAwZIkkaOHOn6GAAAAP1Nn72zlZWVJZ/Pp5ycHB08eDBs2d69e5Wdna3Fixdr2LBhGjdunNasWaO2trYu9xcKhRQMBsMmAACA/sZ4bPl8Pm3ZskWBQEC7d+9Wenq6cnJyVFFR4axz/Phx7dq1S21tbdq/f7+WL1+un/3sZ1q9enWX+y0qKpLX63Wm1NRU06cCAADgmmXbtn3NG1uWSktLNXv2bFfb+f1+WZalvXv3SpJuvfVWff7556qtrVV0dLQkacOGDVq3bp0aGho63UcoFFIoFHLmg8GgUlNT1dTUFPZuGAAAQG8LBoPyer3d6g7X72z1hkmTJqmkpMSZ9/l8GjBggBNakjRmzBg1NjaqtbVVAwcO7LAPj8cjj8fTJ+MFAAC4VhH5PVtVVVXy+XzO/JQpU1RTU6P29nbns6NHj8rn83UaWgAAANcL10+2mpubVVNT48zX1taqurpaiYmJGjFihAoLC1VfX68dO3ZIkjZu3Ki0tDRlZGSotbVVJSUlCgQCCgQCzj4WLVqkZ599VkuWLNFjjz2mY8eOac2aNXr88cd74RQBAAAix3VsVVZWavr06c58fn6+JCkvL0/FxcVqaGjQiRMnnOWtra1atmyZ6uvrFRcXp4yMDO3bt08zZ8501klNTVVZWZmWLl2q8ePHKyUlRUuWLNEPf/jDnpwbAABAxPXoBfn+xM2LagAAAD3hpjv424gAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGuY6tiooK+f1+JScny7Is7dmz56rrl5eXy7KsDtPhw4c7Xf/FF1+UZVmaPXu226EBAAD0OzFuN2hpaVFmZqYWLlyoOXPmdHu7I0eOKD4+3pkfOnRoh3U++ugjLVu2THfeeafbYQEAAPRLrmMrNzdXubm5rg+UlJSkhISELpe3tbXpoYce0qpVq/Tb3/5WZ86ccX0MAACA/qbP3tnKysqSz+dTTk6ODh482GH5T37yEw0dOlR///d/3639hUIhBYPBsAkAAKC/MR5bPp9PW7ZsUSAQ0O7du5Wenq6cnBxVVFQ467z55pvatm2btm7d2u39FhUVyev1OlNqaqqJ4QMAAPSI6x8jupWenq709HRnPjs7W3V1dVq/fr2mTZums2fP6rvf/a62bt2qv/7rv+72fgsLC5Wfn+/MB4NBggsAAPQ7xmOrM5MmTVJJSYkk6cMPP9Sf/vQn+f1+Z3l7e/vFwcXE6MiRIxo1alSHfXg8Hnk8nr4ZMAAAwDWKSGxVVVXJ5/NJkm677Ta99957YcuXL1+us2fP6he/+AVPqwAAwHXNdWw1NzerpqbGma+trVV1dbUSExM1YsQIFRYWqr6+Xjt27JAkbdy4UWlpacrIyFBra6tKSkoUCAQUCAQkSbGxsRo3blzYMS79X4tXfg4AAHC9cR1blZWVmj59ujN/6b2pvLw8FRcXq6GhQSdOnHCWt7a2atmyZaqvr1dcXJwyMjK0b98+zZw5sxeGDwAA0L9Ztm3bkR5EbwgGg/J6vWpqagr75akAAAC9zU138LcRAQAADIrIC/LXo5LffaT1vz6i0IU2XWizdb79hnggCOAGZUnqja9SlqSvp3h14vQ5hS60S7L1+fl22ZJSEmL1ZkGO8/WxJXTB+do4PsWrY6fO6vPz7fp6ilf/r6VVE0YO0YEPGvXZ+XbFDYjSE7PG6v/83zq9W98kSc5nkvRc+YeaMHKIKo5+LEmadutQ599f8USr/sznSkmI1emWVn12/uL/wT4gytJXPDFh6y67N11v157WvndPatb4ZN1+S6JW7X1f59ttpSTESrK06K5R+u6kkSr53Udave8DZ3yjkwbr/ZNNmjU+Wc88mCXp4veCS2N756NPw8a47N50fXfSSEnSfc++oXfrm5SSEKuWUJtzDu989KkW3TXKOccr/31p+85c/n3IExPtHO/Kz7s6ztX2feUxrjyfy8/98uvlZt+dHau723d27EvjvPx8rzbeSOLHiN005anXVH/ms17fLwBcz/701Kxuf32MtqS2y77jpCTEddguJSFOklR/5rOw9a/ctrvHSUmIU2PTZ2qzL35+s7fzY75ZcHeX5xFtSR8WzZL0v98LLh3jymO9WXC3JCmtYF+X47r8HK/896XtO3Pl+Load1fHudq+OzvGldtcWnblcbu7766O1Z3tuzr2led7tfH2Nn6MaMCiu0YpIW6A4gZEaUCUFenhAMBV9dZXKUsXn1Jd/PoXrbgBUc6+Lz4Z+t+vj5d/bRyf4nXWHZ/iVUpCnGaNT1bcgIvfduIGRGnRXaM0PsXrbHPps0V3jXLWT4gboIS4AWH/vnTclIRYZ3/SxSdbV6676K5RmjU+WdGWNGt8shbdNcoZZ0pCrFIS4pwnQIvuGhU2vvEpXme7Sy4f25VjvLSfS+d/6RiXn8Ol413az5X/vprLvw9dfrwrP+/qON1xaV9Xns/l5375cd3su7NjdXf7zo7d2XW91v2bxpMtAAAAl3iyBQAA0E8QWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAYRWwAAAAa5jq2Kigr5/X4lJyfLsizt2bPnquuXl5fLsqwO0+HDh511tm7dqjvvvFNDhgzRkCFDdM899+jtt992fTIAAAD9jevYamlpUWZmpjZt2uRquyNHjqihocGZRo8e7SwrLy/Xgw8+qIMHD+rQoUMaMWKEZsyYofr6erfDAwAA6Fdi3G6Qm5ur3Nxc1wdKSkpSQkJCp8t27twZNr9161bt2rVLv/nNb7RgwQLXxwIAAOgv+uydraysLPl8PuXk5OjgwYNXXffcuXM6f/68EhMTu1wnFAopGAyGTQAAAP2N8djy+XzasmWLAoGAdu/erfT0dOXk5KiioqLLbQoKCpSSkqJ77rmny3WKiork9XqdKTU11cTwAQAAesSybdu+5o0tS6WlpZo9e7ar7fx+vyzL0t69ezssW7t2rZ566imVl5dr/PjxXe4jFAopFAo588FgUKmpqWpqalJ8fLyr8QAAALgRDAbl9Xq71R0R+dUPkyZN0rFjxzp8vn79eq1Zs0ZlZWVXDS1J8ng8io+PD5sAAAD6G9cvyPeGqqoq+Xy+sM/WrVunn/70p/r1r3+tiRMnRmJYAAAAvc51bDU3N6umpsaZr62tVXV1tRITEzVixAgVFhaqvr5eO3bskCRt3LhRaWlpysjIUGtrq0pKShQIBBQIBJx9rF27VitWrNCvfvUrpaWlqbGxUZI0aNAgDRo0qKfnCAAAEDGuY6uyslLTp0935vPz8yVJeXl5Ki4uVkNDg06cOOEsb21t1bJly1RfX6+4uDhlZGRo3759mjlzprPO5s2b1draqu985zthx1q5cqX+9V//1e0QAQAA+o0evSDfn7h5UQ0AAKAn+v0L8gAAAF8WxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBxBYAAIBBrmOroqJCfr9fycnJsixLe/bsuer65eXlsiyrw3T48OGw9QKBgMaOHSuPx6OxY8eqtLTU7dAAAAD6Hdex1dLSoszMTG3atMnVdkeOHFFDQ4MzjR492ll26NAhPfDAA5o/f77+8Ic/aP78+br//vv1+9//3u3wAAAA+hXLtm37mje2LJWWlmr27NldrlNeXq7p06fr008/VUJCQqfrPPDAAwoGg3r55Zedz771rW9pyJAheuGFF7o1lmAwKK/Xq6amJsXHx7s5DQAAAFfcdEefvbOVlZUln8+nnJwcHTx4MGzZoUOHNGPGjLDP7r33Xr311ltd7i8UCikYDIZNAAAA/Y3x2PL5fNqyZYsCgYB2796t9PR05eTkqKKiwlmnsbFRw4YNC9tu2LBhamxs7HK/RUVF8nq9zpSammrsHAAAAK5VjOkDpKenKz093ZnPzs5WXV2d1q9fr2nTpjmfW5YVtp1t2x0+u1xhYaHy8/Od+WAwSHABAIB+JyK/+mHSpEk6duyYM3/zzTd3eIp16tSpDk+7LufxeBQfHx82AQAA9DcRia2qqir5fD5nPjs7WwcOHAhbp6ysTJMnT+7roQEAAPQq1z9GbG5uVk1NjTNfW1ur6upqJSYmasSIESosLFR9fb127NghSdq4caPS0tKUkZGh1tZWlZSUKBAIKBAIOPtYsmSJpk2bpqefflrf/va39R//8R969dVX9cYbb/TCKQIAAESO69iqrKzU9OnTnflL703l5eWpuLhYDQ0NOnHihLO8tbVVy5YtU319veLi4pSRkaF9+/Zp5syZzjqTJ0/Wiy++qOXLl2vFihUaNWqUXnrpJd1xxx09OTcAAICI69Hv2epP+D1bAACgr/TL37MFAADwZURsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGOQ6tioqKuT3+5WcnCzLsrRnz55ub/vmm28qJiZG3/jGNzos27hxo9LT0xUXF6fU1FQtXbpUn3/+udvhAQAA9CuuY6ulpUWZmZnatGmTq+2ampq0YMEC5eTkdFi2c+dOFRQUaOXKlfrv//5vbdu2TS+99JIKCwvdDg8AAKBfiXG7QW5urnJzc10f6JFHHtG8efMUHR3d4WnYoUOHNGXKFM2bN0+SlJaWpgcffFBvv/226+MAAAD0J33yztbzzz+vDz/8UCtXrux0+dSpU/XOO+84cXX8+HHt379fs2bN6nKfoVBIwWAwbAIAAOhvXD/ZcuvYsWMqKCjQb3/7W8XEdH64uXPn6uOPP9bUqVNl27YuXLigRYsWqaCgoMv9FhUVadWqVaaGDQAA0CuMPtlqa2vTvHnztGrVKt16661drldeXq7Vq1dr8+bN+q//+i/t3r1b//mf/6knn3yyy20KCwvV1NTkTHV1dSZOAQAAoEcs27bta97YslRaWqrZs2d3uvzMmTMaMmSIoqOjnc/a29tl27aio6NVVlamu+++W3feeacmTZqkdevWOeuVlJToe9/7npqbmxUV9cVNGAwG5fV61dTUpPj4+Gs9JQAAgC/kpjuM/hgxPj5e7733Xthnmzdv1muvvaZdu3bplltukSSdO3euQ1BFR0fLtm31oAUBAAAiznVsNTc3q6amxpmvra1VdXW1EhMTNWLECBUWFqq+vl47duxQVFSUxo0bF7Z9UlKSYmNjwz73+/3asGGDsrKydMcdd6impkYrVqzQfffdF/ZUDAAA4HrjOrYqKys1ffp0Zz4/P1+SlJeXp+LiYjU0NOjEiROu9rl8+XJZlqXly5ervr5eQ4cOld/v1+rVq90ODwAAoF/p0Ttb/QnvbAEAgL7ipjv424gAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGEVsAAAAGuY6tiooK+f1+JScny7Is7dmzp9vbvvnmm4qJidE3vvGNDsvOnDmjxYsXy+fzKTY2VmPGjNH+/fvdDg8AAKBfiXG7QUtLizIzM7Vw4ULNmTOn29s1NTVpwYIFysnJ0V/+8pewZa2trfrmN7+ppKQk7dq1S8OHD1ddXZ0GDx7sdngAAAD9iuvYys3NVW5urusDPfLII5o3b56io6M7PA3bvn27Tp8+rbfeeksDBgyQJI0cOdL1MQAAAPqbPnln6/nnn9eHH36olStXdrp87969ys7O1uLFizVs2DCNGzdOa9asUVtbW5f7DIVCCgaDYRMAAEB/Yzy2jh07poKCAu3cuVMxMZ0/SDt+/Lh27dqltrY27d+/X8uXL9fPfvYzrV69usv9FhUVyev1OlNqaqqpUwAAALhmRmOrra1N8+bN06pVq3Trrbd2uV57e7uSkpK0ZcsWTZgwQXPnztUTTzyh5557rsttCgsL1dTU5Ex1dXUmTgEAAKBHXL+z5cbZs2dVWVmpqqoqPfroo5IuhpVt24qJiVFZWZnuvvtu+Xw+DRgwQNHR0c62Y8aMUWNjo1pbWzVw4MAO+/Z4PPJ4PCaHDwAA0GNGYys+Pl7vvfde2GebN2/Wa6+9pl27dumWW26RJE2ZMkW/+tWv1N7erqioiw/bjh49Kp/P12loAQAAXC9cx1Zzc7Nqamqc+draWlVXVysxMVEjRoxQYWGh6uvrtWPHDkVFRWncuHFh2yclJSk2Njbs80WLFunZZ5/VkiVL9Nhjj+nYsWNas2aNHn/88R6cGgAAQOS5jq3KykpNnz7dmc/Pz5ck5eXlqbi4WA0NDTpx4oSrfaampqqsrExLly7V+PHjlZKSoiVLluiHP/yh2+EBAAD0K5Zt23akB9EbgsGgvF6vmpqaFB8fH+nhAACAG5ib7uBvIwIAABhEbAEAABhEbAEAABhEbAEAABhEbAEAABhEbAEAABhEbAEAABhEbAEAABhEbAEAABhEbAEAABhEbAEAABhEbAEAABhEbAEAABhEbAEAABgUE+kB9BbbtiVJwWAwwiMBAAA3uku9cak/ruaGia2zZ89KklJTUyM8EgAA8GVx9uxZeb3eq65j2d1JsutAe3u7Tp48qcGDB8uyrEgPp1cEg0Glpqaqrq5O8fHxkR7OlwLXPDK47n2Pa973uOaRYeq627ats2fPKjk5WVFRV38r64Z5shUVFaXhw4dHehhGxMfH8x9mH+OaRwbXve9xzfse1zwyTFz3L3qidQkvyAMAABhEbAEAABhEbPVjHo9HK1eulMfjifRQvjS45pHBde97XPO+xzWPjP5w3W+YF+QBAAD6I55sAQAAGERsAQAAGERsAQAAGERsAQAAGERsAQAAGERsRUhFRYX8fr+Sk5NlWZb27Nnzhdu8/vrrmjBhgmJjY/XVr35V//Zv/2Z+oDcYt9e9vLxclmV1mA4fPtw3A77OFRUV6W/+5m80ePBgJSUlafbs2Tpy5MgXbse93jPXct2513vmueee0/jx453fUp6dna2XX375qttwn/ec2+seqfuc2IqQlpYWZWZmatOmTd1av7a2VjNnztSdd96pqqoq/ehHP9Ljjz+uQCBgeKQ3FrfX/ZIjR46ooaHBmUaPHm1ohDeW119/XYsXL9bvfvc7HThwQBcuXNCMGTPU0tLS5Tbc6z13Ldf9Eu71azN8+HA99dRTqqysVGVlpe6++259+9vf1vvvv9/p+tznvcPtdb+kz+9zGxEnyS4tLb3qOv/yL/9i33bbbWGfPfLII/akSZMMjuzG1p3rfvDgQVuS/emnn/bJmG50p06dsiXZr7/+epfrcK/3vu5cd+713jdkyBD73//93ztdxn1uztWue6Tuc55sXScOHTqkGTNmhH127733qrKyUufPn4/QqL48srKy5PP5lJOTo4MHD0Z6ONetpqYmSVJiYmKX63Cv977uXPdLuNd7rq2tTS+++KJaWlqUnZ3d6Trc572vO9f9kr6+z4mt60RjY6OGDRsW9tmwYcN04cIFffLJJxEa1Y3P5/Npy5YtCgQC2r17t9LT05WTk6OKiopID+26Y9u28vPzNXXqVI0bN67L9bjXe1d3rzv3es+99957GjRokDwej/7pn/5JpaWlGjt2bKfrcp/3HjfXPVL3eYzRvaNXWZYVNm//z19auvJz9J709HSlp6c789nZ2aqrq9P69es1bdq0CI7s+vPoo4/q3Xff1RtvvPGF63Kv957uXnfu9Z5LT09XdXW1zpw5o0AgoLy8PL3++utdfuPnPu8dbq57pO5znmxdJ26++WY1NjaGfXbq1CnFxMTopptuitCovpwmTZqkY8eORXoY15XHHntMe/fu1cGDBzV8+PCrrsu93nvcXPfOcK+7M3DgQH3ta1/TxIkTVVRUpMzMTP3iF7/odF3u897j5rp3pi/uc2LrOpGdna0DBw6EfVZWVqaJEydqwIABERrVl1NVVZV8Pl+kh3FdsG1bjz76qHbv3q3XXntNt9xyyxduw73ec9dy3TvDvd4ztm0rFAp1uoz73JyrXffO9Ml93qev48Nx9uxZu6qqyq6qqrIl2Rs2bLCrqqrsjz76yLZt2y4oKLDnz5/vrH/8+HH7r/7qr+ylS5faH3zwgb1t2zZ7wIAB9q5duyJ1Ctclt9f95z//uV1aWmofPXrU/uMf/2gXFBTYkuxAIBCpU7iuLFq0yPZ6vXZ5ebnd0NDgTOfOnXPW4V7vfddy3bnXe6awsNCuqKiwa2tr7Xfffdf+0Y9+ZEdFRdllZWW2bXOfm+L2ukfqPie2IuTS/3565ZSXl2fbtm3n5eXZf/u3fxu2TXl5uZ2VlWUPHDjQTktLs5977rm+H/h1zu11f/rpp+1Ro0bZsbGx9pAhQ+ypU6fa+/bti8zgr0OdXWtJ9vPPP++sw73e+67lunOv98zDDz9sjxw50h44cKA9dOhQOycnx/mGb9vc56a4ve6Rus8t2/6fN/IAAADQ63hnCwAAwCBiCwAAwCBiCwAAwCBiCwAAwCBiCwAAwCBiCwAAwCBiCwAAwCBiCwAAwCBiCwAAwCBiCwAAwCBiCwAAwKD/D5Y9ZYoFl4b5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "fig, axs = plt.subplots(figsize=(7, 6))\n",
    "axs.scatter(y_test, y_pred_nn, s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34964172-07a8-404e-a3f9-48388e14f236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Variational AutoEncoder",
   "language": "python",
   "name": "o2vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
